{"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"vscode":{"interpreter":{"hash":"9bf73cbd865082e3cd06c05babb8829fd907c8e55c85361e30fff74a8577746e"}}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Imports","metadata":{}},{"cell_type":"code","source":"import warnings\nwarnings.filterwarnings(\"ignore\")\n\nimport os\nimport re\nimport torch\nimport mne\nmne.set_log_level(verbose=None)\n\nfrom tqdm import tqdm\nimport numpy as np\nfrom matplotlib import pyplot as plt\n\nfrom sklearn.model_selection import StratifiedShuffleSplit\nfrom sklearn.metrics import classification_report\nfrom sklearn.utils import class_weight\nfrom sklearn.metrics import confusion_matrix\nfrom sklearn.metrics import plot_confusion_matrix\n\nimport tensorflow as tf\nfrom tensorflow.keras.models import Model\nfrom tensorflow.keras.layers import Dense, Activation, Permute, Dropout\nfrom tensorflow.keras.layers import Conv2D, MaxPooling2D, AveragePooling2D\nfrom tensorflow.keras.layers import SeparableConv2D, DepthwiseConv2D\nfrom tensorflow.keras.layers import BatchNormalization\nfrom tensorflow.keras.layers import SpatialDropout2D\nfrom tensorflow.keras.regularizers import l1_l2\nfrom tensorflow.keras.layers import Input, Flatten\nfrom tensorflow.keras.constraints import max_norm\nfrom tensorflow.keras import backend as K\nfrom tensorflow.keras.losses import BinaryCrossentropy, SparseCategoricalCrossentropy,CategoricalCrossentropy\nfrom tensorflow.keras.optimizers import Adam\nfrom tensorflow.keras.metrics import BinaryAccuracy, AUC, Precision, Recall, CategoricalAccuracy\nfrom tensorflow.keras.callbacks import ModelCheckpoint, ReduceLROnPlateau, EarlyStopping","metadata":{"execution":{"iopub.status.busy":"2022-11-27T16:44:47.073098Z","iopub.execute_input":"2022-11-27T16:44:47.073815Z","iopub.status.idle":"2022-11-27T16:44:47.083782Z","shell.execute_reply.started":"2022-11-27T16:44:47.073778Z","shell.execute_reply":"2022-11-27T16:44:47.082575Z"},"trusted":true},"execution_count":185,"outputs":[]},{"cell_type":"markdown","source":"# Mode","metadata":{}},{"cell_type":"code","source":"MODE = \"CLASSIC\"\n# MODE = \"DOUBLE\" # we double the size of the training subset by mixing the same amount of generated signals as the number in the original subset (6)\n# MODE = \"PRETRAIN\" # pre-train EEGNet on the generated data and then re-train this initialized model with the real signals (7)\n\nDATA = \"BCICIV\"\n# DATA = \"VEPESS\"","metadata":{"execution":{"iopub.status.busy":"2022-11-27T16:44:47.085885Z","iopub.execute_input":"2022-11-27T16:44:47.086248Z","iopub.status.idle":"2022-11-27T16:44:47.099410Z","shell.execute_reply.started":"2022-11-27T16:44:47.086210Z","shell.execute_reply":"2022-11-27T16:44:47.098397Z"},"trusted":true},"execution_count":186,"outputs":[]},{"cell_type":"markdown","source":"# Global variables","metadata":{}},{"cell_type":"code","source":"BCICIV_PATH = \"/kaggle/input/eegpreprocessed/pt_bciciv\"\nVEPESS_PATH = \"/kaggle/input/eegpreprocessed/pt_vepess\"\nBCICIV_AUG_PATH = \"/kaggle/input/eegpreprocessed/pt_bciciv_aug\"\nVEPESS_AUG_PATH = \"/kaggle/input/eegpreprocessed/pt_vepess_aug\"\nN_TENSORS = -1\n \nif DATA == \"BCICIV\":\n    PATH = BCICIV_PATH\n    if MODE == \"AUGMENTED\": PATH_AUG = BCICIV_AUG_PATH\n    N_CLASSES = 4\n    classnames = [\"0\", \"1\", \"2\", \"3\"]\n    N_CHANNELS = 25\n    N_SAMPLES = 448\nelif DATA == \"VEPESS\":\n    PATH = VEPESS_PATH\n    if MODE == \"AUGMENTED\": PATH_AUG = VEPESS_AUG_PATH\n    N_CLASSES = 2\n    classnames = [\"34\", \"35\"]\n    N_CHANNELS = 70\n    N_SAMPLES = 512\n\nBATCH_SIZE = 64\nSHUFFLE_BUFFER_SIZE = BATCH_SIZE * 2 \n\nFIRST_SPLIT = 0.12\nSECOND_SPLIT = 0.15\n\nEPOCHS = 200\nLEARNING_RATE = 1e-3\nMIN_DELTA = 1e-5\nPATIENCE = 20","metadata":{"execution":{"iopub.status.busy":"2022-11-27T16:44:47.102829Z","iopub.execute_input":"2022-11-27T16:44:47.103225Z","iopub.status.idle":"2022-11-27T16:44:47.111777Z","shell.execute_reply.started":"2022-11-27T16:44:47.103194Z","shell.execute_reply":"2022-11-27T16:44:47.110572Z"},"trusted":true},"execution_count":187,"outputs":[]},{"cell_type":"markdown","source":"# Preprocessing data functions","metadata":{}},{"cell_type":"code","source":"# Already sampled / preprocessed\ndef load_pt_data(path):\n    cpt = 0\n    data, labels, users = [], [], []\n    for filename in tqdm(os.listdir(path)):\n        if cpt >= N_TENSORS and N_TENSORS != -1:\n            break\n        f = os.path.join(path, filename)\n        x, y, u = torch.load(f)\n        data.append(x)\n        labels.append(y)\n        users.append(u)\n        cpt += 1\n    return np.array(data), np.array(labels), np.array(users)\n\ndef split_data(preprocessed_data, final_labels, final_user_idx):\n    split = StratifiedShuffleSplit(n_splits=2, test_size=FIRST_SPLIT, random_state=0)\n    for x_index, test_index in split.split(preprocessed_data, final_user_idx):\n        X, X_test = preprocessed_data[x_index], preprocessed_data[test_index]\n        y, y_test = final_labels[x_index], final_labels[test_index]\n        users, users_test = final_user_idx[x_index], final_user_idx[test_index]\n#     print(X.shape, X_test.shape, y.shape, y_test.shape)\n#     print(np.unique(users, return_counts=True), np.unique(users_test, return_counts=True))\n    split = StratifiedShuffleSplit(n_splits=2, test_size=SECOND_SPLIT, random_state=0)\n    for train_index, valid_index in split.split(X, users):\n        X_train, X_valid = X[train_index], X[valid_index] \n        y_train, y_valid = y[train_index], y[valid_index]\n        users_train, users_valid = users[train_index], users[valid_index]\n#     print(X_train.shape, X_valid.shape, y_train.shape, y_valid.shape)\n#     print(np.unique(y_train, return_counts=True), np.unique(y_test, return_counts=True))\n#     print(np.unique(users_train, return_counts=True))\n#     print(np.unique(users_valid, return_counts=True))\n#     print(np.unique(users_test, return_counts=True))\n    return X_train, y_train, X_valid, y_valid, X_test, y_test\n\ndef one_hot_data(y_train, y_valid, y_test):\n    if DATA == \"VEPESS\":\n        y_train = np.where(y_train==34, 0, 1)\n        y_valid = np.where(y_valid==34, 0, 1)\n        y_test = np.where(y_test==34, 0, 1)\n    else:\n        y_train = y_train - 1\n        y_valid = y_valid - 1\n        y_test = y_test - 1\n    y_train = tf.one_hot(y_train, depth=N_CLASSES, axis=0)\n    y_valid = tf.one_hot(y_valid, depth=N_CLASSES, axis=0)\n    y_test = tf.one_hot(y_test, depth=N_CLASSES, axis=0)\n    return tf.transpose(y_train), tf.transpose(y_valid), tf.transpose(y_test)\n\ndef make_tensorflow_dataset(X_train, y_train, X_valid, y_valid, X_test, y_test):\n    train_dataset = tf.data.Dataset.from_tensor_slices((X_train, y_train))\n    valid_dataset = tf.data.Dataset.from_tensor_slices((X_valid, y_valid))\n    test_dataset = tf.data.Dataset.from_tensor_slices((X_test, y_test))\n    train_dataset = train_dataset.shuffle(SHUFFLE_BUFFER_SIZE).batch(BATCH_SIZE)\n    valid_dataset = valid_dataset.shuffle(SHUFFLE_BUFFER_SIZE).batch(BATCH_SIZE)\n    test_dataset = test_dataset.batch(BATCH_SIZE)\n    return train_dataset, valid_dataset, test_dataset","metadata":{"execution":{"iopub.status.busy":"2022-11-27T16:44:47.115987Z","iopub.execute_input":"2022-11-27T16:44:47.116284Z","iopub.status.idle":"2022-11-27T16:44:47.132360Z","shell.execute_reply.started":"2022-11-27T16:44:47.116258Z","shell.execute_reply":"2022-11-27T16:44:47.131518Z"},"trusted":true},"execution_count":188,"outputs":[]},{"cell_type":"markdown","source":"# Preprocessing data","metadata":{}},{"cell_type":"code","source":"if MODE == \"CLASSIC\":\n    data = load_pt_data(PATH)\n    X_train, y_train, X_valid, y_valid, X_test, y_test = split_data(data[0], data[1], data[2])\n    y_train, y_valid, y_test = one_hot_data(y_train, y_valid, y_test)\n    train_dataset, valid_dataset, test_dataset = make_tensorflow_dataset(X_train, \n                                                                         y_train, \n                                                                         X_valid, \n                                                                         y_valid, \n                                                                         X_test, \n                                                                         y_test)\nelif MODE == \"DOUBLE\":\n    data_base = load_pt_data(PATH)\n    data_aug = load_pt_data(PATH_AUG)\n    data = data_base + data_aug\n    X_train, y_train, X_valid, y_valid, X_test, y_test = split_data(data[0], data[1], data[2])\n    y_train, y_valid, y_test = one_hot_data(y_train, y_valid, y_test)\n    train_dataset, valid_dataset, test_dataset = make_tensorflow_dataset(X_train, \n                                                                         y_train, \n                                                                         X_valid, \n                                                                         y_valid, \n                                                                         X_test, \n                                                                         y_test)\nelif MODE == \"PRETRAIN\":\n    data_base = load_pt_data(PATH)\n    X_train, y_train, X_valid, y_valid, X_test, y_test = split_data(data_base[0], data_base[1], data_base[2])\n    y_train, y_valid, y_test = one_hot_data(y_train, y_valid, y_test)\n    train_dataset, valid_dataset, test_dataset = make_tensorflow_dataset(X_train, \n                                                                         y_train, \n                                                                         X_valid, \n                                                                         y_valid, \n                                                                         X_test, \n                                                                         y_test)\n    data_aug = load_pt_data(PATH_AUG)\n    X_train_aug, y_train, X_valid, y_valid, X_test, y_test = split_data(data_aug[0], data_aug[1], data_aug[2])\n    y_train_aug, y_valid_aug, y_test_aug = one_hot_data(y_train_aug, y_valid_aug, y_test_aug)\n    train_dataset_aug, valid_dataset_aug, test_dataset_aug = make_tensorflow_dataset(X_train_aug, \n                                                                                     y_train_aug, \n                                                                                     X_valid_aug, \n                                                                                     y_valid_aug, \n                                                                                     X_test_aug, \n                                                                                     y_test_aug)","metadata":{"execution":{"iopub.status.busy":"2022-11-27T16:44:47.207650Z","iopub.execute_input":"2022-11-27T16:44:47.208294Z","iopub.status.idle":"2022-11-27T16:44:51.517813Z","shell.execute_reply.started":"2022-11-27T16:44:47.208259Z","shell.execute_reply":"2022-11-27T16:44:51.516707Z"},"trusted":true},"execution_count":189,"outputs":[{"name":"stderr","text":"100%|██████████| 2592/2592 [00:03<00:00, 730.49it/s]\n","output_type":"stream"}]},{"cell_type":"code","source":"print(np.unique(y_train.numpy().argmax(axis=1), return_counts=True))\nprint(np.unique(y_valid.numpy().argmax(axis=1), return_counts=True))\nprint(np.unique(y_test.numpy().argmax(axis=1), return_counts=True))\nprint(X_train.min(), X_train.max(), X_train.mean(), X_train.std())","metadata":{"execution":{"iopub.status.busy":"2022-11-27T16:44:51.520121Z","iopub.execute_input":"2022-11-27T16:44:51.520454Z","iopub.status.idle":"2022-11-27T16:44:51.676234Z","shell.execute_reply.started":"2022-11-27T16:44:51.520426Z","shell.execute_reply":"2022-11-27T16:44:51.675061Z"},"trusted":true},"execution_count":190,"outputs":[{"name":"stdout","text":"(array([0, 1, 2, 3]), array([481, 490, 484, 483]))\n(array([0, 1, 2, 3]), array([94, 77, 86, 85]))\n(array([0, 1, 2, 3]), array([73, 81, 78, 80]))\n-1.0 1.0 0.019062353726686045 0.34398400833170356\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# Model functions","metadata":{}},{"cell_type":"code","source":"def get_callbacks():\n    return [\n        # ModelCheckpoint(\n        #     \"best_eegnet.h5\", save_best_only=True, monitor=\"val_loss\"\n        # ),\n        # ReduceLROnPlateau(\n        #     monitor=\"val_top_k_categorical_accuracy\",\n        #     factor=0.2,\n        #     patience=2,\n        #     min_lr=0.000001,\n        # ),\n        EarlyStopping(\n            monitor=\"val_loss\",\n            min_delta=MIN_DELTA,\n            patience=PATIENCE,\n            verbose=1,\n            mode=\"auto\",\n            baseline=None,\n            restore_best_weights=True,\n        ),\n    ]\n\n# https://arxiv.org/pdf/1611.08024.pdf\ndef EEGNet(n_classes, n_channels=64, n_samples=128, kernel_length=64, n_filters1=8, \n           n_filters2=16, depth_multiplier=2, norm_rate=0.25, dropout_rate=0.5, \n           dropoutType=\"Dropout\"):\n\n    if dropoutType == \"SpatialDropout2D\":\n        dropoutType=SpatialDropout2D\n    elif dropoutType == \"Dropout\":\n        dropoutType=Dropout\n\n    inputs = Input(shape=(n_channels, n_samples, 1))\n\n    block1 = Conv2D(n_filters1, (1, kernel_length), padding=\"same\", input_shape=(n_channels, n_samples, 1), use_bias=False)(inputs)\n    block1 = BatchNormalization()(block1)\n    block1 = DepthwiseConv2D((n_channels, 1), use_bias=False, depth_multiplier=depth_multiplier, depthwise_constraint=max_norm(1.0))(block1)\n    block1 = BatchNormalization()(block1)\n    block1 = Activation(\"elu\")(block1)\n    block1 = AveragePooling2D((1, 4))(block1)\n    block1 = dropoutType(dropout_rate)(block1)\n\n    block2 = SeparableConv2D(n_filters2, (1, 16), use_bias=False, padding=\"same\")(block1)\n    block2 = BatchNormalization()(block2)\n    block2 = Activation(\"elu\")(block2)\n    block2 = AveragePooling2D((1, 8))(block2)\n    block2 = dropoutType(dropout_rate)(block2)\n    block2 = Flatten(name=\"flatten\")(block2)\n\n    classifier = Dense(n_classes, name=\"dense\", kernel_constraint=max_norm(norm_rate))(block2)\n    classifier = Activation(\"softmax\", name=\"softmax\")(classifier)\n\n    model = Model(inputs=inputs, outputs=classifier) \n\n    optimizer = Adam(amsgrad=True, learning_rate=LEARNING_RATE)\n    \n    if DATA == \"BCICIV\":\n        loss = CategoricalCrossentropy()\n        acc = CategoricalAccuracy()\n    elif DATA == \"VEPESS\":\n        loss = BinaryCrossentropy()\n        acc = BinaryAccuracy()\n        \n    model.compile(\n            optimizer=optimizer,\n            loss=loss,\n            metrics=[\n                acc,\n    #             AUC(),\n    #             Precision(),\n    #             Recall(),\n            ],\n        )\n\n    model.summary()\n\n    return model\n\ndef plot_history_metrics(history):\n    total_plots = len(history.history)\n    cols = total_plots // 2\n\n    rows = total_plots // cols\n\n    if total_plots % cols != 0:\n        rows += 1\n\n    pos = range(1, total_plots + 1)\n    plt.figure(figsize=(15, 10))\n    for i, (key, value) in enumerate(history.history.items()):\n        plt.subplot(rows, cols, pos[i])\n        plt.plot(range(len(value)), value)\n        plt.title(str(key))\n    plt.show()","metadata":{"execution":{"iopub.status.busy":"2022-11-27T16:44:51.678059Z","iopub.execute_input":"2022-11-27T16:44:51.678458Z","iopub.status.idle":"2022-11-27T16:44:51.696087Z","shell.execute_reply.started":"2022-11-27T16:44:51.678420Z","shell.execute_reply":"2022-11-27T16:44:51.694761Z"},"trusted":true},"execution_count":191,"outputs":[]},{"cell_type":"markdown","source":"# Training","metadata":{}},{"cell_type":"code","source":"classes = np.unique(y_train.numpy().argmax(axis=1))\nclass_weights = class_weight.compute_class_weight(class_weight=\"balanced\", classes=classes, y=y_train.numpy().argmax(axis=1))\nclass_weights = dict(zip(classes, class_weights))\nprint(class_weights)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"if MODE == \"CLASSIC\" or MODE == \"DOUBLE\":\n    model = EEGNet(n_classes=N_CLASSES, n_channels=N_CHANNELS, n_samples=N_SAMPLES)\n    history = model.fit(\n        train_dataset,\n        epochs=EPOCHS,\n        callbacks=get_callbacks(),\n        validation_data=valid_dataset,\n        class_weight=class_weights,\n    )\nelif MODE == \"PRETRAIN\":\n    model = EEGNet(n_classes=N_CLASSES, n_channels=N_CHANNELS, n_samples=N_SAMPLES)  \n    pretrain_history = model.fit(\n        train_dataset_aug,\n        epochs=EPOCHS,\n        callbacks=get_callbacks(),\n        validation_data=valid_dataset_aug,\n        class_weight=class_weights_aug,\n    )\n    final_history = model.fit(\n        train_dataset,\n        epochs=EPOCHS,\n        callbacks=get_callbacks(),\n        validation_data=valid_dataset,\n        class_weight=class_weights_aug,\n    )","metadata":{"execution":{"iopub.status.busy":"2022-11-27T16:44:51.698269Z","iopub.execute_input":"2022-11-27T16:44:51.698767Z"},"trusted":true},"execution_count":null,"outputs":[{"name":"stdout","text":"Model: \"model_11\"\n_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\ninput_12 (InputLayer)        [(None, 25, 448, 1)]      0         \n_________________________________________________________________\nconv2d_11 (Conv2D)           (None, 25, 448, 8)        512       \n_________________________________________________________________\nbatch_normalization_33 (Batc (None, 25, 448, 8)        32        \n_________________________________________________________________\ndepthwise_conv2d_11 (Depthwi (None, 1, 448, 16)        400       \n_________________________________________________________________\nbatch_normalization_34 (Batc (None, 1, 448, 16)        64        \n_________________________________________________________________\nactivation_22 (Activation)   (None, 1, 448, 16)        0         \n_________________________________________________________________\naverage_pooling2d_22 (Averag (None, 1, 112, 16)        0         \n_________________________________________________________________\ndropout_22 (Dropout)         (None, 1, 112, 16)        0         \n_________________________________________________________________\nseparable_conv2d_11 (Separab (None, 1, 112, 16)        512       \n_________________________________________________________________\nbatch_normalization_35 (Batc (None, 1, 112, 16)        64        \n_________________________________________________________________\nactivation_23 (Activation)   (None, 1, 112, 16)        0         \n_________________________________________________________________\naverage_pooling2d_23 (Averag (None, 1, 14, 16)         0         \n_________________________________________________________________\ndropout_23 (Dropout)         (None, 1, 14, 16)         0         \n_________________________________________________________________\nflatten (Flatten)            (None, 224)               0         \n_________________________________________________________________\ndense (Dense)                (None, 4)                 900       \n_________________________________________________________________\nsoftmax (Activation)         (None, 4)                 0         \n=================================================================\nTotal params: 2,484\nTrainable params: 2,404\nNon-trainable params: 80\n_________________________________________________________________\n{0: 1.0072765072765073, 1: 0.9887755102040816, 2: 1.0010330578512396, 3: 1.0031055900621118}\nEpoch 1/200\n31/31 [==============================] - 2s 35ms/step - loss: 1.3969 - categorical_accuracy: 0.2405 - val_loss: 1.3864 - val_categorical_accuracy: 0.2251\nEpoch 2/200\n31/31 [==============================] - 1s 32ms/step - loss: 1.3848 - categorical_accuracy: 0.2570 - val_loss: 1.3863 - val_categorical_accuracy: 0.2924\nEpoch 3/200\n31/31 [==============================] - 1s 39ms/step - loss: 1.3736 - categorical_accuracy: 0.2879 - val_loss: 1.3878 - val_categorical_accuracy: 0.2749\nEpoch 4/200\n31/31 [==============================] - 1s 31ms/step - loss: 1.3558 - categorical_accuracy: 0.3225 - val_loss: 1.3970 - val_categorical_accuracy: 0.2749\nEpoch 5/200\n31/31 [==============================] - 1s 31ms/step - loss: 1.3439 - categorical_accuracy: 0.3385 - val_loss: 1.4104 - val_categorical_accuracy: 0.2749\nEpoch 6/200\n31/31 [==============================] - 1s 31ms/step - loss: 1.3274 - categorical_accuracy: 0.3524 - val_loss: 1.4262 - val_categorical_accuracy: 0.2749\nEpoch 7/200\n31/31 [==============================] - 1s 31ms/step - loss: 1.3301 - categorical_accuracy: 0.3607 - val_loss: 1.4228 - val_categorical_accuracy: 0.2749\nEpoch 8/200\n31/31 [==============================] - 1s 31ms/step - loss: 1.3255 - categorical_accuracy: 0.3720 - val_loss: 1.4230 - val_categorical_accuracy: 0.2749\nEpoch 9/200\n31/31 [==============================] - 1s 31ms/step - loss: 1.3217 - categorical_accuracy: 0.3566 - val_loss: 1.4057 - val_categorical_accuracy: 0.2895\nEpoch 10/200\n31/31 [==============================] - 1s 32ms/step - loss: 1.3136 - categorical_accuracy: 0.3633 - val_loss: 1.3954 - val_categorical_accuracy: 0.3012\nEpoch 11/200\n31/31 [==============================] - 1s 32ms/step - loss: 1.3129 - categorical_accuracy: 0.3725 - val_loss: 1.3785 - val_categorical_accuracy: 0.3275\nEpoch 12/200\n31/31 [==============================] - 1s 31ms/step - loss: 1.3167 - categorical_accuracy: 0.3725 - val_loss: 1.3571 - val_categorical_accuracy: 0.3421\nEpoch 13/200\n31/31 [==============================] - 1s 31ms/step - loss: 1.3042 - categorical_accuracy: 0.3705 - val_loss: 1.3507 - val_categorical_accuracy: 0.3480\nEpoch 14/200\n31/31 [==============================] - 1s 31ms/step - loss: 1.2938 - categorical_accuracy: 0.3824 - val_loss: 1.3223 - val_categorical_accuracy: 0.3684\nEpoch 15/200\n31/31 [==============================] - 1s 31ms/step - loss: 1.2839 - categorical_accuracy: 0.4045 - val_loss: 1.3004 - val_categorical_accuracy: 0.3772\nEpoch 16/200\n31/31 [==============================] - 1s 31ms/step - loss: 1.2800 - categorical_accuracy: 0.4087 - val_loss: 1.2739 - val_categorical_accuracy: 0.4240\nEpoch 17/200\n31/31 [==============================] - 1s 32ms/step - loss: 1.2609 - categorical_accuracy: 0.4128 - val_loss: 1.2674 - val_categorical_accuracy: 0.4269\nEpoch 18/200\n31/31 [==============================] - 1s 32ms/step - loss: 1.2582 - categorical_accuracy: 0.4247 - val_loss: 1.2502 - val_categorical_accuracy: 0.4327\nEpoch 19/200\n31/31 [==============================] - 1s 31ms/step - loss: 1.2602 - categorical_accuracy: 0.4226 - val_loss: 1.2492 - val_categorical_accuracy: 0.4094\nEpoch 20/200\n31/31 [==============================] - 1s 32ms/step - loss: 1.2578 - categorical_accuracy: 0.4407 - val_loss: 1.2446 - val_categorical_accuracy: 0.4211\nEpoch 21/200\n31/31 [==============================] - 1s 31ms/step - loss: 1.2418 - categorical_accuracy: 0.4283 - val_loss: 1.2341 - val_categorical_accuracy: 0.4357\nEpoch 22/200\n31/31 [==============================] - 1s 31ms/step - loss: 1.2513 - categorical_accuracy: 0.4314 - val_loss: 1.2383 - val_categorical_accuracy: 0.4327\nEpoch 23/200\n31/31 [==============================] - 1s 31ms/step - loss: 1.2391 - categorical_accuracy: 0.4262 - val_loss: 1.2414 - val_categorical_accuracy: 0.4211\nEpoch 24/200\n31/31 [==============================] - 1s 31ms/step - loss: 1.2413 - categorical_accuracy: 0.4190 - val_loss: 1.2517 - val_categorical_accuracy: 0.4181\nEpoch 25/200\n31/31 [==============================] - 1s 31ms/step - loss: 1.2361 - categorical_accuracy: 0.4345 - val_loss: 1.2367 - val_categorical_accuracy: 0.4327\nEpoch 26/200\n31/31 [==============================] - 1s 31ms/step - loss: 1.2404 - categorical_accuracy: 0.4319 - val_loss: 1.2398 - val_categorical_accuracy: 0.4357\nEpoch 27/200\n31/31 [==============================] - 1s 31ms/step - loss: 1.2277 - categorical_accuracy: 0.4319 - val_loss: 1.2245 - val_categorical_accuracy: 0.4298\nEpoch 28/200\n31/31 [==============================] - 1s 36ms/step - loss: 1.2307 - categorical_accuracy: 0.4489 - val_loss: 1.2288 - val_categorical_accuracy: 0.4327\nEpoch 29/200\n31/31 [==============================] - 1s 31ms/step - loss: 1.2273 - categorical_accuracy: 0.4324 - val_loss: 1.2265 - val_categorical_accuracy: 0.4444\nEpoch 30/200\n31/31 [==============================] - 1s 33ms/step - loss: 1.2232 - categorical_accuracy: 0.4479 - val_loss: 1.2305 - val_categorical_accuracy: 0.4269\nEpoch 31/200\n31/31 [==============================] - 1s 32ms/step - loss: 1.2151 - categorical_accuracy: 0.4577 - val_loss: 1.2394 - val_categorical_accuracy: 0.4327\nEpoch 32/200\n31/31 [==============================] - 1s 32ms/step - loss: 1.2091 - categorical_accuracy: 0.4520 - val_loss: 1.2293 - val_categorical_accuracy: 0.4444\nEpoch 33/200\n31/31 [==============================] - 1s 31ms/step - loss: 1.2097 - categorical_accuracy: 0.4608 - val_loss: 1.2353 - val_categorical_accuracy: 0.4357\nEpoch 34/200\n31/31 [==============================] - 1s 33ms/step - loss: 1.2213 - categorical_accuracy: 0.4355 - val_loss: 1.2253 - val_categorical_accuracy: 0.4415\nEpoch 35/200\n31/31 [==============================] - 1s 31ms/step - loss: 1.2054 - categorical_accuracy: 0.4618 - val_loss: 1.2385 - val_categorical_accuracy: 0.4444\nEpoch 36/200\n31/31 [==============================] - 1s 32ms/step - loss: 1.1948 - categorical_accuracy: 0.4598 - val_loss: 1.2270 - val_categorical_accuracy: 0.4561\nEpoch 37/200\n31/31 [==============================] - 1s 32ms/step - loss: 1.1878 - categorical_accuracy: 0.4613 - val_loss: 1.2185 - val_categorical_accuracy: 0.4532\nEpoch 38/200\n31/31 [==============================] - 1s 32ms/step - loss: 1.2048 - categorical_accuracy: 0.4510 - val_loss: 1.2358 - val_categorical_accuracy: 0.4240\nEpoch 39/200\n31/31 [==============================] - 1s 31ms/step - loss: 1.1998 - categorical_accuracy: 0.4567 - val_loss: 1.2222 - val_categorical_accuracy: 0.4327\nEpoch 40/200\n31/31 [==============================] - 1s 31ms/step - loss: 1.1774 - categorical_accuracy: 0.4721 - val_loss: 1.2221 - val_categorical_accuracy: 0.4357\nEpoch 41/200\n31/31 [==============================] - 1s 31ms/step - loss: 1.2016 - categorical_accuracy: 0.4494 - val_loss: 1.2200 - val_categorical_accuracy: 0.4503\nEpoch 42/200\n31/31 [==============================] - 1s 32ms/step - loss: 1.1883 - categorical_accuracy: 0.4515 - val_loss: 1.2156 - val_categorical_accuracy: 0.4444\nEpoch 43/200\n31/31 [==============================] - 1s 31ms/step - loss: 1.1858 - categorical_accuracy: 0.4639 - val_loss: 1.2269 - val_categorical_accuracy: 0.4532\nEpoch 44/200\n31/31 [==============================] - 1s 31ms/step - loss: 1.1799 - categorical_accuracy: 0.4732 - val_loss: 1.2059 - val_categorical_accuracy: 0.4503\nEpoch 45/200\n31/31 [==============================] - 1s 31ms/step - loss: 1.1776 - categorical_accuracy: 0.4690 - val_loss: 1.2083 - val_categorical_accuracy: 0.4503\nEpoch 46/200\n31/31 [==============================] - 1s 31ms/step - loss: 1.1899 - categorical_accuracy: 0.4716 - val_loss: 1.2093 - val_categorical_accuracy: 0.4503\nEpoch 47/200\n31/31 [==============================] - 1s 32ms/step - loss: 1.1838 - categorical_accuracy: 0.4520 - val_loss: 1.2010 - val_categorical_accuracy: 0.4474\nEpoch 48/200\n31/31 [==============================] - 1s 31ms/step - loss: 1.1781 - categorical_accuracy: 0.4809 - val_loss: 1.2016 - val_categorical_accuracy: 0.4561\nEpoch 49/200\n31/31 [==============================] - 1s 31ms/step - loss: 1.1809 - categorical_accuracy: 0.4587 - val_loss: 1.1907 - val_categorical_accuracy: 0.4561\nEpoch 50/200\n31/31 [==============================] - 1s 31ms/step - loss: 1.1680 - categorical_accuracy: 0.4783 - val_loss: 1.1914 - val_categorical_accuracy: 0.4561\nEpoch 51/200\n31/31 [==============================] - 1s 31ms/step - loss: 1.1703 - categorical_accuracy: 0.4835 - val_loss: 1.1946 - val_categorical_accuracy: 0.4649\nEpoch 52/200\n31/31 [==============================] - 1s 31ms/step - loss: 1.1578 - categorical_accuracy: 0.4742 - val_loss: 1.1914 - val_categorical_accuracy: 0.4474\nEpoch 53/200\n31/31 [==============================] - 1s 34ms/step - loss: 1.1684 - categorical_accuracy: 0.4716 - val_loss: 1.1997 - val_categorical_accuracy: 0.4532\nEpoch 54/200\n31/31 [==============================] - 1s 31ms/step - loss: 1.1681 - categorical_accuracy: 0.4716 - val_loss: 1.1901 - val_categorical_accuracy: 0.4678\nEpoch 55/200\n31/31 [==============================] - 1s 33ms/step - loss: 1.1554 - categorical_accuracy: 0.4747 - val_loss: 1.2019 - val_categorical_accuracy: 0.4678\nEpoch 56/200\n31/31 [==============================] - 1s 34ms/step - loss: 1.1561 - categorical_accuracy: 0.4902 - val_loss: 1.1976 - val_categorical_accuracy: 0.4737\nEpoch 57/200\n31/31 [==============================] - 1s 31ms/step - loss: 1.1474 - categorical_accuracy: 0.4969 - val_loss: 1.1892 - val_categorical_accuracy: 0.4591\nEpoch 58/200\n31/31 [==============================] - 1s 31ms/step - loss: 1.1485 - categorical_accuracy: 0.4866 - val_loss: 1.1992 - val_categorical_accuracy: 0.4649\nEpoch 59/200\n31/31 [==============================] - 1s 31ms/step - loss: 1.1452 - categorical_accuracy: 0.4892 - val_loss: 1.2061 - val_categorical_accuracy: 0.4386\nEpoch 60/200\n31/31 [==============================] - 1s 31ms/step - loss: 1.1399 - categorical_accuracy: 0.4985 - val_loss: 1.1854 - val_categorical_accuracy: 0.4503\nEpoch 61/200\n31/31 [==============================] - 1s 31ms/step - loss: 1.1485 - categorical_accuracy: 0.4670 - val_loss: 1.1980 - val_categorical_accuracy: 0.4474\nEpoch 62/200\n31/31 [==============================] - 1s 31ms/step - loss: 1.1380 - categorical_accuracy: 0.4923 - val_loss: 1.1944 - val_categorical_accuracy: 0.4591\nEpoch 63/200\n31/31 [==============================] - 1s 31ms/step - loss: 1.1389 - categorical_accuracy: 0.4835 - val_loss: 1.2077 - val_categorical_accuracy: 0.4649\nEpoch 64/200\n31/31 [==============================] - 1s 31ms/step - loss: 1.1341 - categorical_accuracy: 0.4943 - val_loss: 1.1952 - val_categorical_accuracy: 0.4415\nEpoch 65/200\n31/31 [==============================] - 1s 33ms/step - loss: 1.1175 - categorical_accuracy: 0.5041 - val_loss: 1.1923 - val_categorical_accuracy: 0.4474\nEpoch 66/200\n31/31 [==============================] - 1s 31ms/step - loss: 1.1278 - categorical_accuracy: 0.4959 - val_loss: 1.1910 - val_categorical_accuracy: 0.4620\nEpoch 67/200\n31/31 [==============================] - 1s 31ms/step - loss: 1.1387 - categorical_accuracy: 0.4902 - val_loss: 1.1885 - val_categorical_accuracy: 0.4737\nEpoch 68/200\n31/31 [==============================] - 1s 31ms/step - loss: 1.1343 - categorical_accuracy: 0.5093 - val_loss: 1.1846 - val_categorical_accuracy: 0.4561\nEpoch 69/200\n31/31 [==============================] - 1s 31ms/step - loss: 1.1389 - categorical_accuracy: 0.5036 - val_loss: 1.1831 - val_categorical_accuracy: 0.4649\nEpoch 70/200\n31/31 [==============================] - 1s 31ms/step - loss: 1.1217 - categorical_accuracy: 0.5139 - val_loss: 1.1903 - val_categorical_accuracy: 0.4474\nEpoch 71/200\n31/31 [==============================] - 1s 31ms/step - loss: 1.1277 - categorical_accuracy: 0.4928 - val_loss: 1.1808 - val_categorical_accuracy: 0.4766\nEpoch 72/200\n31/31 [==============================] - 1s 31ms/step - loss: 1.1257 - categorical_accuracy: 0.4892 - val_loss: 1.1810 - val_categorical_accuracy: 0.4678\nEpoch 73/200\n31/31 [==============================] - 1s 31ms/step - loss: 1.1321 - categorical_accuracy: 0.4995 - val_loss: 1.1877 - val_categorical_accuracy: 0.4649\nEpoch 74/200\n31/31 [==============================] - 1s 31ms/step - loss: 1.1252 - categorical_accuracy: 0.4974 - val_loss: 1.1868 - val_categorical_accuracy: 0.4649\nEpoch 75/200\n31/31 [==============================] - 1s 31ms/step - loss: 1.1118 - categorical_accuracy: 0.5021 - val_loss: 1.1742 - val_categorical_accuracy: 0.4708\nEpoch 76/200\n31/31 [==============================] - 1s 31ms/step - loss: 1.1343 - categorical_accuracy: 0.4902 - val_loss: 1.2009 - val_categorical_accuracy: 0.4357\nEpoch 77/200\n31/31 [==============================] - 1s 30ms/step - loss: 1.1332 - categorical_accuracy: 0.4948 - val_loss: 1.1788 - val_categorical_accuracy: 0.4561\nEpoch 78/200\n31/31 [==============================] - 1s 31ms/step - loss: 1.1345 - categorical_accuracy: 0.4881 - val_loss: 1.1712 - val_categorical_accuracy: 0.4620\nEpoch 79/200\n31/31 [==============================] - 1s 33ms/step - loss: 1.1272 - categorical_accuracy: 0.4959 - val_loss: 1.1821 - val_categorical_accuracy: 0.4678\nEpoch 80/200\n31/31 [==============================] - 1s 33ms/step - loss: 1.1242 - categorical_accuracy: 0.4990 - val_loss: 1.1771 - val_categorical_accuracy: 0.4561\nEpoch 81/200\n31/31 [==============================] - 1s 31ms/step - loss: 1.1179 - categorical_accuracy: 0.4964 - val_loss: 1.1804 - val_categorical_accuracy: 0.4678\nEpoch 82/200\n31/31 [==============================] - 1s 31ms/step - loss: 1.1082 - categorical_accuracy: 0.4990 - val_loss: 1.1793 - val_categorical_accuracy: 0.4708\nEpoch 83/200\n31/31 [==============================] - 1s 31ms/step - loss: 1.1221 - categorical_accuracy: 0.4948 - val_loss: 1.1632 - val_categorical_accuracy: 0.4532\nEpoch 84/200\n31/31 [==============================] - 1s 32ms/step - loss: 1.1196 - categorical_accuracy: 0.4979 - val_loss: 1.1657 - val_categorical_accuracy: 0.5029\nEpoch 85/200\n31/31 [==============================] - 1s 31ms/step - loss: 1.1183 - categorical_accuracy: 0.4912 - val_loss: 1.2093 - val_categorical_accuracy: 0.4444\nEpoch 86/200\n31/31 [==============================] - 1s 31ms/step - loss: 1.1125 - categorical_accuracy: 0.4969 - val_loss: 1.1773 - val_categorical_accuracy: 0.4649\nEpoch 87/200\n31/31 [==============================] - 1s 31ms/step - loss: 1.1149 - categorical_accuracy: 0.4954 - val_loss: 1.1769 - val_categorical_accuracy: 0.4678\nEpoch 88/200\n31/31 [==============================] - 1s 31ms/step - loss: 1.1125 - categorical_accuracy: 0.4938 - val_loss: 1.1751 - val_categorical_accuracy: 0.4591\nEpoch 89/200\n31/31 [==============================] - 1s 32ms/step - loss: 1.1099 - categorical_accuracy: 0.4995 - val_loss: 1.1745 - val_categorical_accuracy: 0.4737\nEpoch 90/200\n31/31 [==============================] - 1s 31ms/step - loss: 1.1104 - categorical_accuracy: 0.5036 - val_loss: 1.1696 - val_categorical_accuracy: 0.4737\nEpoch 91/200\n31/31 [==============================] - 1s 31ms/step - loss: 1.1044 - categorical_accuracy: 0.5217 - val_loss: 1.1878 - val_categorical_accuracy: 0.4532\nEpoch 92/200\n31/31 [==============================] - 1s 31ms/step - loss: 1.0956 - categorical_accuracy: 0.5052 - val_loss: 1.1694 - val_categorical_accuracy: 0.4766\nEpoch 93/200\n31/31 [==============================] - 1s 32ms/step - loss: 1.0963 - categorical_accuracy: 0.5175 - val_loss: 1.1636 - val_categorical_accuracy: 0.4678\nEpoch 94/200\n31/31 [==============================] - 1s 31ms/step - loss: 1.1090 - categorical_accuracy: 0.5124 - val_loss: 1.1715 - val_categorical_accuracy: 0.4854\nEpoch 95/200\n31/31 [==============================] - 1s 31ms/step - loss: 1.0999 - categorical_accuracy: 0.5139 - val_loss: 1.1691 - val_categorical_accuracy: 0.4708\nEpoch 96/200\n31/31 [==============================] - 1s 31ms/step - loss: 1.1168 - categorical_accuracy: 0.5021 - val_loss: 1.1637 - val_categorical_accuracy: 0.4561\nEpoch 97/200\n31/31 [==============================] - 1s 31ms/step - loss: 1.1186 - categorical_accuracy: 0.4979 - val_loss: 1.1602 - val_categorical_accuracy: 0.4708\nEpoch 98/200\n31/31 [==============================] - 1s 31ms/step - loss: 1.1021 - categorical_accuracy: 0.5206 - val_loss: 1.1674 - val_categorical_accuracy: 0.4737\nEpoch 99/200\n31/31 [==============================] - 1s 31ms/step - loss: 1.0986 - categorical_accuracy: 0.5124 - val_loss: 1.1618 - val_categorical_accuracy: 0.4620\nEpoch 100/200\n31/31 [==============================] - 1s 32ms/step - loss: 1.0985 - categorical_accuracy: 0.5139 - val_loss: 1.1737 - val_categorical_accuracy: 0.4532\nEpoch 101/200\n31/31 [==============================] - 1s 31ms/step - loss: 1.1084 - categorical_accuracy: 0.5150 - val_loss: 1.1770 - val_categorical_accuracy: 0.4561\nEpoch 102/200\n31/31 [==============================] - 1s 32ms/step - loss: 1.1024 - categorical_accuracy: 0.5052 - val_loss: 1.1714 - val_categorical_accuracy: 0.4708\nEpoch 103/200\n31/31 [==============================] - 1s 31ms/step - loss: 1.1274 - categorical_accuracy: 0.5000 - val_loss: 1.1676 - val_categorical_accuracy: 0.4649\nEpoch 104/200\n31/31 [==============================] - 1s 31ms/step - loss: 1.1157 - categorical_accuracy: 0.5098 - val_loss: 1.1705 - val_categorical_accuracy: 0.4620\nEpoch 105/200\n31/31 [==============================] - 1s 33ms/step - loss: 1.0953 - categorical_accuracy: 0.5129 - val_loss: 1.1666 - val_categorical_accuracy: 0.4737\nEpoch 106/200\n31/31 [==============================] - 1s 36ms/step - loss: 1.0936 - categorical_accuracy: 0.5170 - val_loss: 1.1818 - val_categorical_accuracy: 0.4415\nEpoch 107/200\n31/31 [==============================] - 1s 32ms/step - loss: 1.1160 - categorical_accuracy: 0.5175 - val_loss: 1.1643 - val_categorical_accuracy: 0.4912\nEpoch 108/200\n31/31 [==============================] - 1s 31ms/step - loss: 1.1016 - categorical_accuracy: 0.5046 - val_loss: 1.1668 - val_categorical_accuracy: 0.4620\nEpoch 109/200\n31/31 [==============================] - 1s 31ms/step - loss: 1.0922 - categorical_accuracy: 0.5083 - val_loss: 1.1708 - val_categorical_accuracy: 0.4766\nEpoch 110/200\n31/31 [==============================] - 1s 32ms/step - loss: 1.0917 - categorical_accuracy: 0.5139 - val_loss: 1.1653 - val_categorical_accuracy: 0.4649\nEpoch 111/200\n31/31 [==============================] - 1s 32ms/step - loss: 1.1027 - categorical_accuracy: 0.5083 - val_loss: 1.1599 - val_categorical_accuracy: 0.4708\nEpoch 112/200\n31/31 [==============================] - 1s 31ms/step - loss: 1.0898 - categorical_accuracy: 0.5217 - val_loss: 1.1619 - val_categorical_accuracy: 0.4708\nEpoch 113/200\n21/31 [===================>..........] - ETA: 0s - loss: 1.0868 - categorical_accuracy: 0.5171","output_type":"stream"}]},{"cell_type":"markdown","source":"# Plotting learning curves","metadata":{}},{"cell_type":"code","source":"if MODE == \"CLASSIC\" or MODE == \"DOUBLE\":\n    plot_history_metrics(history)\nelif MODE == \"PRETRAIN\":\n    plot_history_metrics(pretrain_history)\n    plot_history_metrics(final_history)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Final evaluation on test set","metadata":{}},{"cell_type":"code","source":"# Trick to use plot function from sklearn\nclass estimator:\n    _estimator_type = \"\"\n    classes_=[]\n    def __init__(self, model, classes):\n        self.model = model\n        self._estimator_type = \"classifier\"\n        self.classes_ = classes\n    def predict(self, X):\n        y_prob= self.model.predict(X)\n        y_pred = y_prob.argmax(axis=1)\n        return y_pred\n\nclassifier = estimator(model, classnames)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"color = \"white\"\n\nmatrix = plot_confusion_matrix(classifier, X_train, y_train.numpy().argmax(axis=1), cmap=plt.cm.Blues)\nmatrix.ax_.set_title(\"Train confusion matrix\", color=color)\nplt.xlabel(\"Predicted Label\", color=color)\nplt.ylabel(\"True Label\", color=color)\nplt.gcf().axes[0].tick_params(colors=color)\nplt.gcf().axes[1].tick_params(colors=color)\nplt.show()\n\nmatrix = plot_confusion_matrix(classifier, X_valid, y_valid.numpy().argmax(axis=1), cmap=plt.cm.Blues)\nmatrix.ax_.set_title(\"Valid confusion matrix\", color=color)\nplt.xlabel(\"Predicted Label\", color=color)\nplt.ylabel(\"True Label\", color=color)\nplt.gcf().axes[0].tick_params(colors=color)\nplt.gcf().axes[1].tick_params(colors=color)\nplt.show()\n\nmatrix = plot_confusion_matrix(classifier, X_test, y_test.numpy().argmax(axis=1), cmap=plt.cm.Blues)\nmatrix.ax_.set_title(\"Test confusion matrix\", color=color)\nplt.xlabel(\"Predicted Label\", color=color)\nplt.ylabel(\"True Label\", color=color)\nplt.gcf().axes[0].tick_params(colors=color)\nplt.gcf().axes[1].tick_params(colors=color)\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y_pred = model.predict(X_test).argmax(axis=1)\ny_true = y_test.numpy().argmax(axis=1)\nprint(classification_report(y_true, y_pred))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}