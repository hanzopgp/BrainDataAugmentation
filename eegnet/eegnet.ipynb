{"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"vscode":{"interpreter":{"hash":"9bf73cbd865082e3cd06c05babb8829fd907c8e55c85361e30fff74a8577746e"}}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import numpy as np\nfrom matplotlib import pyplot as plt\nimport mne\nmne.set_log_level(verbose=None)\nimport tensorflow as tf\nimport os\nimport re\nfrom tqdm import tqdm\n\nfrom sklearn.model_selection import StratifiedShuffleSplit\n\nfrom tensorflow.keras.models import Model\nfrom tensorflow.keras.layers import Dense, Activation, Permute, Dropout\nfrom tensorflow.keras.layers import Conv2D, MaxPooling2D, AveragePooling2D\nfrom tensorflow.keras.layers import SeparableConv2D, DepthwiseConv2D\nfrom tensorflow.keras.layers import BatchNormalization\nfrom tensorflow.keras.layers import SpatialDropout2D\nfrom tensorflow.keras.regularizers import l1_l2\nfrom tensorflow.keras.layers import Input, Flatten\nfrom tensorflow.keras.constraints import max_norm\nfrom tensorflow.keras import backend as K\nfrom tensorflow.keras.losses import BinaryCrossentropy\nfrom tensorflow.keras.optimizers import Adam\nfrom tensorflow.keras.metrics import TopKCategoricalAccuracy, AUC, Precision, Recall\nfrom tensorflow.keras.callbacks import ModelCheckpoint, ReduceLROnPlateau, EarlyStopping","metadata":{"execution":{"iopub.status.busy":"2022-11-20T19:35:53.906968Z","iopub.execute_input":"2022-11-20T19:35:53.907863Z","iopub.status.idle":"2022-11-20T19:36:01.658828Z","shell.execute_reply.started":"2022-11-20T19:35:53.907766Z","shell.execute_reply":"2022-11-20T19:36:01.657817Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"N_FILES = -1\n\nN_CLASSES = 2\nN_CHANNELS = 25\nN_SAMPLES = 128\n\nWHERE = \"kaggle\"\nif WHERE==\"colab\":\n    BCICIV_PATH = \"/content/BCICIV_2a_gdf\"\n    BATCH_SIZE = 32\nelif WHERE==\"kaggle\":\n    BCICIV_PATH = \"../input/eeg-data-augmentation/BCICIV_2a_gdf\"\n    BATCH_SIZE = 64\nelif WHERE==\"home\":\n    PATH_LABELS = \"../toy_data/BCICIV_2a_gdf\"\n    BATCH_SIZE = 4\nSHUFFLE_BUFFER_SIZE = BATCH_SIZE * 2 \n\nFIRST_SPLIT = 0.12\nSECOND_SPLIT = 0.15\n\nEPOCHS = 5\nLEARNING_RATE = 1e-3","metadata":{"execution":{"iopub.status.busy":"2022-11-20T19:36:01.660870Z","iopub.execute_input":"2022-11-20T19:36:01.661466Z","iopub.status.idle":"2022-11-20T19:36:01.672351Z","shell.execute_reply.started":"2022-11-20T19:36:01.661436Z","shell.execute_reply":"2022-11-20T19:36:01.670494Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"raw","source":"def load_data():\n    files = []\n    user_idx = []\n    labels = []\n    cpt = 0\n    for filename in os.listdir(BCICIV_PATH):\n        # Get the right number of files\n        if cpt >= N_FILES and N_FILES != -1:\n            break\n        # Get labels\n        if \"E\" in filename:\n            labels.append(\"E\")\n        elif \"T\" in filename:\n            labels.append(\"T\")\n        # Get user idx\n        idx = str(re.findall(r'\\d+', filename)[0])\n        user_idx.append(idx.lstrip(\"0\"))\n        data = mne.io.read_raw_gdf(f'{BCICIV_PATH}/{filename}', preload=True)\n        data.set_eeg_reference()\n#         data.filter(l_freq=0.5, h_freq=45)\n#         data = mne.make_fixed_length_epochs(data, duration=5)\n        files.append(data)\n        cpt += 1\n    return files, user_idx, labels\n\n## NEED TO SPLIT OUR DATA IS BATCHES OF LENGTH 128 FOR EACH FILES\ndef preprocess_data(data, user_idx, labels):\n    # Extracting the data\n    d0 = data[0].get_data().T\n    d0 = np.array(np.split(d0[:len(d0)-(len(d0)%N_SAMPLES)], len(d0)//N_SAMPLES))\n    size = d0.shape[0]*d0.shape[1]\n    preprocessed_data = d0\n    final_user_idx = user_idx[0] * size\n    final_labels = labels[0] * size\n    cpt = 1\n    for d in tqdm(data[1:]):\n        d = d.get_data().T\n        \n        d = np.array(np.split(d[:len(d)-(len(d)%N_SAMPLES)], len(d)//N_SAMPLES))\n        size = d.shape[0]*d.shape[1]\n        preprocessed_data = np.concatenate((preprocessed_data, d), axis=0)\n        \n        final_user_idx = final_user_idx + (user_idx[cpt] * size)\n        final_labels = final_labels + (labels[cpt] * size)\n        cpt += 1\n    n_ex, n_sample, n_chans = preprocessed_data.shape\n    final_user_idx = np.array(list(final_user_idx))\n    final_labels = np.array(list(final_labels))\n    print(\"--> This dataset contains\", n_ex, \"examples,\", n_chans, \"channels and size of sample is\", n_sample)\n    print(\"--> 25 channels: 22 EEG and 3 EOG\")\n    print(\"--> Shape of the users and labels arrays:\", final_user_idx.shape, final_labels.shape)\n    print(\"--> Final shape of data:\", preprocessed_data.shape)\n    \n    # Splitting the data with stratified fold\n    split = StratifiedShuffleSplit(n_splits=2, test_size=FIRST_SPLIT, random_state=0)\n    final_user_idx = final_user_idx.reshape(preprocessed_data.shape[0], preprocessed_data.shape[1])\n    for x_index, test_index in split.split(preprocessed_data, final_user_idx):\n        X, X_test = preprocessed_data[x_index], preprocessed_data[test_index]\n        y, y_test = final_labels[x_index], final_labels[test_index]\n        users, users_test = final_user_idx[x_index], final_user_idx[test_index]\n#     print(X.shape, X_test.shape, y.shape, y_test.shape)\n#     print(np.unique(users, return_counts=True), np.unique(users_test, return_counts=True))\n\n    split = StratifiedShuffleSplit(n_splits=2, test_size=SECOND_SPLIT, random_state=0)\n    for train_index, valid_index in split.split(X, users):\n        X_train, X_valid = X[train_index], X[valid_index] \n        y_train, y_valid = y[train_index], y[valid_index]\n        users_train, users_valid = users[train_index], users[valid_index]\n#     print(X_train.shape, X_valid.shape, y_train.shape, y_valid.shape)\n#     print(np.unique(y_train, return_counts=True), np.unique(y_test, return_counts=True))\n    \n    # Reshape for our model\n    X_train = np.moveaxis(X_train, 2, 1)\n    X_valid = np.moveaxis(X_valid, 2, 1)\n    X_test = np.moveaxis(X_test, 2, 1)\n    \n    # Preprocess our labels\n    y_train = np.where(y_train==\"E\", 0, 1)\n    y_valid = np.where(y_valid==\"E\", 0, 1)\n    y_test = np.where(y_test==\"E\", 0, 1)\n    y_train = tf.one_hot(y_train, depth=N_CLASSES)\n    y_valid = tf.one_hot(y_valid, depth=N_CLASSES)\n    y_test = tf.one_hot(y_test, depth=N_CLASSES)\n    \n    # Check if our split is well done with respect to user indexes\n    print(X_train.shape, X_valid.shape, X_test.shape, y_train.shape, y_valid.shape, y_test.shape)\n    print(np.unique(users_train, return_counts=True), np.unique(users_valid, return_counts=True), np.unique(users_test, return_counts=True))\n    \n    return X_train, y_train, X_valid, y_valid, X_test, y_test \n\ndef visualize_data():\n    pass\n\ndef make_tf_dataset(X_train, y_train, X_valid, y_valid, X_test, y_test):\n    train_dataset = tf.data.Dataset.from_tensor_slices((X_train, y_train))\n    valid_dataset = tf.data.Dataset.from_tensor_slices((X_valid, y_valid))\n    test_dataset = tf.data.Dataset.from_tensor_slices((X_test, y_test))\n\n    train_dataset = train_dataset.shuffle(SHUFFLE_BUFFER_SIZE).batch(BATCH_SIZE)\n    valid_dataset = valid_dataset.shuffle(SHUFFLE_BUFFER_SIZE).batch(BATCH_SIZE)\n    test_dataset = test_dataset.batch(BATCH_SIZE)\n\n    return train_dataset, valid_dataset, test_dataset","metadata":{}},{"cell_type":"code","source":"data, user_idx, labels = load_data()\nX_train, y_train, X_valid, y_valid, X_test, y_test = preprocess_data(data, user_idx, labels)\ntrain_dataset, valid_dataset, test_dataset = make_tf_dataset(X_train, y_train, X_valid, y_valid, X_test, y_test)","metadata":{"execution":{"iopub.status.busy":"2022-11-20T19:36:01.705529Z","iopub.execute_input":"2022-11-20T19:36:01.706670Z","iopub.status.idle":"2022-11-20T19:37:13.226178Z","shell.execute_reply.started":"2022-11-20T19:36:01.706632Z","shell.execute_reply":"2022-11-20T19:37:13.225230Z"},"trusted":true},"execution_count":4,"outputs":[{"name":"stdout","text":"Extracting EDF parameters from /kaggle/input/eeg-data-augmentation/BCICIV_2a_gdf/A01T.gdf...\nGDF file detected\nSetting channel info structure...\nCould not determine channel type of the following channels, they will be set as EEG:\nEEG-Fz, EEG, EEG, EEG, EEG, EEG, EEG, EEG-C3, EEG, EEG-Cz, EEG, EEG-C4, EEG, EEG, EEG, EEG, EEG, EEG, EEG, EEG-Pz, EEG, EEG, EOG-left, EOG-central, EOG-right\nCreating raw.info structure...\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.7/contextlib.py:119: RuntimeWarning: Channel names are not unique, found duplicates for: {'EEG'}. Applying running numbers for duplicates.\n  next(self.gen)\n","output_type":"stream"},{"name":"stdout","text":"Reading 0 ... 672527  =      0.000 ...  2690.108 secs...\nEEG channel type selected for re-referencing\nApplying average reference.\nApplying a custom ('EEG',) reference.\nExtracting EDF parameters from /kaggle/input/eeg-data-augmentation/BCICIV_2a_gdf/A04E.gdf...\nGDF file detected\nSetting channel info structure...\nCould not determine channel type of the following channels, they will be set as EEG:\nEEG-Fz, EEG, EEG, EEG, EEG, EEG, EEG, EEG-C3, EEG, EEG-Cz, EEG, EEG-C4, EEG, EEG, EEG, EEG, EEG, EEG, EEG, EEG-Pz, EEG, EEG, EOG-left, EOG-central, EOG-right\nCreating raw.info structure...\nReading 0 ... 660046  =      0.000 ...  2640.184 secs...\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.7/contextlib.py:119: RuntimeWarning: Channel names are not unique, found duplicates for: {'EEG'}. Applying running numbers for duplicates.\n  next(self.gen)\n","output_type":"stream"},{"name":"stdout","text":"EEG channel type selected for re-referencing\nApplying average reference.\nApplying a custom ('EEG',) reference.\nExtracting EDF parameters from /kaggle/input/eeg-data-augmentation/BCICIV_2a_gdf/A08T.gdf...\nGDF file detected\nSetting channel info structure...\nCould not determine channel type of the following channels, they will be set as EEG:\nEEG-Fz, EEG, EEG, EEG, EEG, EEG, EEG, EEG-C3, EEG, EEG-Cz, EEG, EEG-C4, EEG, EEG, EEG, EEG, EEG, EEG, EEG, EEG-Pz, EEG, EEG, EOG-left, EOG-central, EOG-right\nCreating raw.info structure...\nReading 0 ... 675269  =      0.000 ...  2701.076 secs...\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.7/contextlib.py:119: RuntimeWarning: Channel names are not unique, found duplicates for: {'EEG'}. Applying running numbers for duplicates.\n  next(self.gen)\n","output_type":"stream"},{"name":"stdout","text":"EEG channel type selected for re-referencing\nApplying average reference.\nApplying a custom ('EEG',) reference.\nExtracting EDF parameters from /kaggle/input/eeg-data-augmentation/BCICIV_2a_gdf/A03E.gdf...\nGDF file detected\nSetting channel info structure...\nCould not determine channel type of the following channels, they will be set as EEG:\nEEG-Fz, EEG, EEG, EEG, EEG, EEG, EEG, EEG-C3, EEG, EEG-Cz, EEG, EEG-C4, EEG, EEG, EEG, EEG, EEG, EEG, EEG, EEG-Pz, EEG, EEG, EOG-left, EOG-central, EOG-right\nCreating raw.info structure...\nReading 0 ... 648774  =      0.000 ...  2595.096 secs...\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.7/contextlib.py:119: RuntimeWarning: Channel names are not unique, found duplicates for: {'EEG'}. Applying running numbers for duplicates.\n  next(self.gen)\n","output_type":"stream"},{"name":"stdout","text":"EEG channel type selected for re-referencing\nApplying average reference.\nApplying a custom ('EEG',) reference.\nExtracting EDF parameters from /kaggle/input/eeg-data-augmentation/BCICIV_2a_gdf/A09E.gdf...\nGDF file detected\nSetting channel info structure...\nCould not determine channel type of the following channels, they will be set as EEG:\nEEG-Fz, EEG, EEG, EEG, EEG, EEG, EEG, EEG-C3, EEG, EEG-Cz, EEG, EEG-C4, EEG, EEG, EEG, EEG, EEG, EEG, EEG, EEG-Pz, EEG, EEG, EOG-left, EOG-central, EOG-right\nCreating raw.info structure...\nReading 0 ... 675097  =      0.000 ...  2700.388 secs...\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.7/contextlib.py:119: RuntimeWarning: Channel names are not unique, found duplicates for: {'EEG'}. Applying running numbers for duplicates.\n  next(self.gen)\n","output_type":"stream"},{"name":"stdout","text":"EEG channel type selected for re-referencing\nApplying average reference.\nApplying a custom ('EEG',) reference.\nExtracting EDF parameters from /kaggle/input/eeg-data-augmentation/BCICIV_2a_gdf/A06E.gdf...\nGDF file detected\nSetting channel info structure...\nCould not determine channel type of the following channels, they will be set as EEG:\nEEG-Fz, EEG, EEG, EEG, EEG, EEG, EEG, EEG-C3, EEG, EEG-Cz, EEG, EEG-C4, EEG, EEG, EEG, EEG, EEG, EEG, EEG, EEG-Pz, EEG, EEG, EOG-left, EOG-central, EOG-right\nCreating raw.info structure...\nReading 0 ... 666372  =      0.000 ...  2665.488 secs...\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.7/contextlib.py:119: RuntimeWarning: Channel names are not unique, found duplicates for: {'EEG'}. Applying running numbers for duplicates.\n  next(self.gen)\n","output_type":"stream"},{"name":"stdout","text":"EEG channel type selected for re-referencing\nApplying average reference.\nApplying a custom ('EEG',) reference.\nExtracting EDF parameters from /kaggle/input/eeg-data-augmentation/BCICIV_2a_gdf/A06T.gdf...\nGDF file detected\nSetting channel info structure...\nCould not determine channel type of the following channels, they will be set as EEG:\nEEG-Fz, EEG, EEG, EEG, EEG, EEG, EEG, EEG-C3, EEG, EEG-Cz, EEG, EEG-C4, EEG, EEG, EEG, EEG, EEG, EEG, EEG, EEG-Pz, EEG, EEG, EOG-left, EOG-central, EOG-right\nCreating raw.info structure...\nReading 0 ... 678979  =      0.000 ...  2715.916 secs...\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.7/contextlib.py:119: RuntimeWarning: Channel names are not unique, found duplicates for: {'EEG'}. Applying running numbers for duplicates.\n  next(self.gen)\n","output_type":"stream"},{"name":"stdout","text":"EEG channel type selected for re-referencing\nApplying average reference.\nApplying a custom ('EEG',) reference.\nExtracting EDF parameters from /kaggle/input/eeg-data-augmentation/BCICIV_2a_gdf/A02T.gdf...\nGDF file detected\nSetting channel info structure...\nCould not determine channel type of the following channels, they will be set as EEG:\nEEG-Fz, EEG, EEG, EEG, EEG, EEG, EEG, EEG-C3, EEG, EEG-Cz, EEG, EEG-C4, EEG, EEG, EEG, EEG, EEG, EEG, EEG, EEG-Pz, EEG, EEG, EOG-left, EOG-central, EOG-right\nCreating raw.info structure...\nReading 0 ... 677168  =      0.000 ...  2708.672 secs...\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.7/contextlib.py:119: RuntimeWarning: Channel names are not unique, found duplicates for: {'EEG'}. Applying running numbers for duplicates.\n  next(self.gen)\n","output_type":"stream"},{"name":"stdout","text":"EEG channel type selected for re-referencing\nApplying average reference.\nApplying a custom ('EEG',) reference.\nExtracting EDF parameters from /kaggle/input/eeg-data-augmentation/BCICIV_2a_gdf/A05E.gdf...\nGDF file detected\nSetting channel info structure...\nCould not determine channel type of the following channels, they will be set as EEG:\nEEG-Fz, EEG, EEG, EEG, EEG, EEG, EEG, EEG-C3, EEG, EEG-Cz, EEG, EEG-C4, EEG, EEG, EEG, EEG, EEG, EEG, EEG, EEG-Pz, EEG, EEG, EOG-left, EOG-central, EOG-right\nCreating raw.info structure...\nReading 0 ... 679862  =      0.000 ...  2719.448 secs...\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.7/contextlib.py:119: RuntimeWarning: Channel names are not unique, found duplicates for: {'EEG'}. Applying running numbers for duplicates.\n  next(self.gen)\n","output_type":"stream"},{"name":"stdout","text":"EEG channel type selected for re-referencing\nApplying average reference.\nApplying a custom ('EEG',) reference.\nExtracting EDF parameters from /kaggle/input/eeg-data-augmentation/BCICIV_2a_gdf/A03T.gdf...\nGDF file detected\nSetting channel info structure...\nCould not determine channel type of the following channels, they will be set as EEG:\nEEG-Fz, EEG, EEG, EEG, EEG, EEG, EEG, EEG-C3, EEG, EEG-Cz, EEG, EEG-C4, EEG, EEG, EEG, EEG, EEG, EEG, EEG, EEG-Pz, EEG, EEG, EOG-left, EOG-central, EOG-right\nCreating raw.info structure...\nReading 0 ... 660529  =      0.000 ...  2642.116 secs...\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.7/contextlib.py:119: RuntimeWarning: Channel names are not unique, found duplicates for: {'EEG'}. Applying running numbers for duplicates.\n  next(self.gen)\n","output_type":"stream"},{"name":"stdout","text":"EEG channel type selected for re-referencing\nApplying average reference.\nApplying a custom ('EEG',) reference.\nExtracting EDF parameters from /kaggle/input/eeg-data-augmentation/BCICIV_2a_gdf/A07E.gdf...\nGDF file detected\nSetting channel info structure...\nCould not determine channel type of the following channels, they will be set as EEG:\nEEG-Fz, EEG, EEG, EEG, EEG, EEG, EEG, EEG-C3, EEG, EEG-Cz, EEG, EEG-C4, EEG, EEG, EEG, EEG, EEG, EEG, EEG, EEG-Pz, EEG, EEG, EOG-left, EOG-central, EOG-right\nCreating raw.info structure...\nReading 0 ... 673134  =      0.000 ...  2692.536 secs...\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.7/contextlib.py:119: RuntimeWarning: Channel names are not unique, found duplicates for: {'EEG'}. Applying running numbers for duplicates.\n  next(self.gen)\n","output_type":"stream"},{"name":"stdout","text":"EEG channel type selected for re-referencing\nApplying average reference.\nApplying a custom ('EEG',) reference.\nExtracting EDF parameters from /kaggle/input/eeg-data-augmentation/BCICIV_2a_gdf/A09T.gdf...\nGDF file detected\nSetting channel info structure...\nCould not determine channel type of the following channels, they will be set as EEG:\nEEG-Fz, EEG, EEG, EEG, EEG, EEG, EEG, EEG-C3, EEG, EEG-Cz, EEG, EEG-C4, EEG, EEG, EEG, EEG, EEG, EEG, EEG, EEG-Pz, EEG, EEG, EOG-left, EOG-central, EOG-right\nCreating raw.info structure...\nReading 0 ... 673327  =      0.000 ...  2693.308 secs...\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.7/contextlib.py:119: RuntimeWarning: Channel names are not unique, found duplicates for: {'EEG'}. Applying running numbers for duplicates.\n  next(self.gen)\n","output_type":"stream"},{"name":"stdout","text":"EEG channel type selected for re-referencing\nApplying average reference.\nApplying a custom ('EEG',) reference.\nExtracting EDF parameters from /kaggle/input/eeg-data-augmentation/BCICIV_2a_gdf/A08E.gdf...\nGDF file detected\nSetting channel info structure...\nCould not determine channel type of the following channels, they will be set as EEG:\nEEG-Fz, EEG, EEG, EEG, EEG, EEG, EEG, EEG-C3, EEG, EEG-Cz, EEG, EEG-C4, EEG, EEG, EEG, EEG, EEG, EEG, EEG, EEG-Pz, EEG, EEG, EOG-left, EOG-central, EOG-right\nCreating raw.info structure...\nReading 0 ... 687791  =      0.000 ...  2751.164 secs...\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.7/contextlib.py:119: RuntimeWarning: Channel names are not unique, found duplicates for: {'EEG'}. Applying running numbers for duplicates.\n  next(self.gen)\n","output_type":"stream"},{"name":"stdout","text":"EEG channel type selected for re-referencing\nApplying average reference.\nApplying a custom ('EEG',) reference.\nExtracting EDF parameters from /kaggle/input/eeg-data-augmentation/BCICIV_2a_gdf/A07T.gdf...\nGDF file detected\nSetting channel info structure...\nCould not determine channel type of the following channels, they will be set as EEG:\nEEG-Fz, EEG, EEG, EEG, EEG, EEG, EEG, EEG-C3, EEG, EEG-Cz, EEG, EEG-C4, EEG, EEG, EEG, EEG, EEG, EEG, EEG, EEG-Pz, EEG, EEG, EOG-left, EOG-central, EOG-right\nCreating raw.info structure...\nReading 0 ... 681070  =      0.000 ...  2724.280 secs...\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.7/contextlib.py:119: RuntimeWarning: Channel names are not unique, found duplicates for: {'EEG'}. Applying running numbers for duplicates.\n  next(self.gen)\n","output_type":"stream"},{"name":"stdout","text":"EEG channel type selected for re-referencing\nApplying average reference.\nApplying a custom ('EEG',) reference.\nExtracting EDF parameters from /kaggle/input/eeg-data-augmentation/BCICIV_2a_gdf/A05T.gdf...\nGDF file detected\nSetting channel info structure...\nCould not determine channel type of the following channels, they will be set as EEG:\nEEG-Fz, EEG, EEG, EEG, EEG, EEG, EEG, EEG-C3, EEG, EEG-Cz, EEG, EEG-C4, EEG, EEG, EEG, EEG, EEG, EEG, EEG, EEG-Pz, EEG, EEG, EOG-left, EOG-central, EOG-right\nCreating raw.info structure...\nReading 0 ... 686119  =      0.000 ...  2744.476 secs...\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.7/contextlib.py:119: RuntimeWarning: Channel names are not unique, found duplicates for: {'EEG'}. Applying running numbers for duplicates.\n  next(self.gen)\n","output_type":"stream"},{"name":"stdout","text":"EEG channel type selected for re-referencing\nApplying average reference.\nApplying a custom ('EEG',) reference.\nExtracting EDF parameters from /kaggle/input/eeg-data-augmentation/BCICIV_2a_gdf/A02E.gdf...\nGDF file detected\nSetting channel info structure...\nCould not determine channel type of the following channels, they will be set as EEG:\nEEG-Fz, EEG, EEG, EEG, EEG, EEG, EEG, EEG-C3, EEG, EEG-Cz, EEG, EEG-C4, EEG, EEG, EEG, EEG, EEG, EEG, EEG, EEG-Pz, EEG, EEG, EOG-left, EOG-central, EOG-right\nCreating raw.info structure...\nReading 0 ... 662665  =      0.000 ...  2650.660 secs...\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.7/contextlib.py:119: RuntimeWarning: Channel names are not unique, found duplicates for: {'EEG'}. Applying running numbers for duplicates.\n  next(self.gen)\n","output_type":"stream"},{"name":"stdout","text":"EEG channel type selected for re-referencing\nApplying average reference.\nApplying a custom ('EEG',) reference.\nExtracting EDF parameters from /kaggle/input/eeg-data-augmentation/BCICIV_2a_gdf/A01E.gdf...\nGDF file detected\nSetting channel info structure...\nCould not determine channel type of the following channels, they will be set as EEG:\nEEG-Fz, EEG, EEG, EEG, EEG, EEG, EEG, EEG-C3, EEG, EEG-Cz, EEG, EEG-C4, EEG, EEG, EEG, EEG, EEG, EEG, EEG, EEG-Pz, EEG, EEG, EOG-left, EOG-central, EOG-right\nCreating raw.info structure...\nReading 0 ... 686999  =      0.000 ...  2747.996 secs...\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.7/contextlib.py:119: RuntimeWarning: Channel names are not unique, found duplicates for: {'EEG'}. Applying running numbers for duplicates.\n  next(self.gen)\n","output_type":"stream"},{"name":"stdout","text":"EEG channel type selected for re-referencing\nApplying average reference.\nApplying a custom ('EEG',) reference.\nExtracting EDF parameters from /kaggle/input/eeg-data-augmentation/BCICIV_2a_gdf/A04T.gdf...\nGDF file detected\nSetting channel info structure...\nCould not determine channel type of the following channels, they will be set as EEG:\nEEG-Fz, EEG, EEG, EEG, EEG, EEG, EEG, EEG-C3, EEG, EEG-Cz, EEG, EEG-C4, EEG, EEG, EEG, EEG, EEG, EEG, EEG, EEG-Pz, EEG, EEG, EOG-left, EOG-central, EOG-right\nCreating raw.info structure...\nReading 0 ... 600914  =      0.000 ...  2403.656 secs...\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.7/contextlib.py:119: RuntimeWarning: Channel names are not unique, found duplicates for: {'EEG'}. Applying running numbers for duplicates.\n  next(self.gen)\n","output_type":"stream"},{"name":"stdout","text":"EEG channel type selected for re-referencing\nApplying average reference.\nApplying a custom ('EEG',) reference.\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 17/17 [00:10<00:00,  1.64it/s]\n","output_type":"stream"},{"name":"stdout","text":"--> This dataset contains 94107 examples, 25 channels and size of sample is 128\n--> 25 channels: 22 EEG and 3 EOG\n--> Shape of the users and labels arrays: (12045696,) (12045696,)\n--> Final shape of data: (94107, 128, 25)\n","output_type":"stream"},{"name":"stderr","text":"2022-11-20 19:37:04.169496: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2022-11-20 19:37:04.259992: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2022-11-20 19:37:04.260784: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2022-11-20 19:37:04.263776: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA\nTo enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n2022-11-20 19:37:04.264124: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2022-11-20 19:37:04.264831: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2022-11-20 19:37:04.265582: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2022-11-20 19:37:06.586661: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2022-11-20 19:37:06.587844: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2022-11-20 19:37:06.588708: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2022-11-20 19:37:06.590209: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1510] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 15401 MB memory:  -> device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:00:04.0, compute capability: 6.0\n","output_type":"stream"},{"name":"stdout","text":"(70391, 25, 128) (12423, 25, 128) (11293, 25, 128) (70391, 2) (12423, 2) (11293, 2)\n(array(['1', '2', '3', '4', '5', '6', '7', '8', '9'], dtype='<U1'), array([1016832, 1002112,  979328,  943104, 1021568, 1006336, 1012864,\n       1019392, 1008512])) (array(['1', '2', '3', '4', '5', '6', '7', '8', '9'], dtype='<U1'), array([179456, 176896, 172800, 166400, 180352, 177536, 178688, 179968,\n       178048])) (array(['1', '2', '3', '4', '5', '6', '7', '8', '9'], dtype='<U1'), array([163200, 160768, 157056, 151296, 163968, 161408, 162432, 163584,\n       161792]))\n","output_type":"stream"},{"name":"stderr","text":"2022-11-20 19:37:08.385152: W tensorflow/core/framework/cpu_allocator_impl.cc:80] Allocation of 1802009600 exceeds 10% of free system memory.\n2022-11-20 19:37:10.370632: W tensorflow/core/framework/cpu_allocator_impl.cc:80] Allocation of 1802009600 exceeds 10% of free system memory.\n2022-11-20 19:37:11.940641: W tensorflow/core/framework/cpu_allocator_impl.cc:80] Allocation of 318028800 exceeds 10% of free system memory.\n2022-11-20 19:37:12.290445: W tensorflow/core/framework/cpu_allocator_impl.cc:80] Allocation of 318028800 exceeds 10% of free system memory.\n2022-11-20 19:37:12.660245: W tensorflow/core/framework/cpu_allocator_impl.cc:80] Allocation of 289100800 exceeds 10% of free system memory.\n","output_type":"stream"}]},{"cell_type":"code","source":"print(np.unique(y_train, return_counts=True))\nprint(np.unique(y_valid, return_counts=True))\nprint(np.unique(y_test, return_counts=True))","metadata":{"execution":{"iopub.status.busy":"2022-11-20T19:39:16.720545Z","iopub.execute_input":"2022-11-20T19:39:16.720904Z","iopub.status.idle":"2022-11-20T19:39:16.735414Z","shell.execute_reply.started":"2022-11-20T19:39:16.720871Z","shell.execute_reply":"2022-11-20T19:39:16.734485Z"},"trusted":true},"execution_count":12,"outputs":[{"name":"stdout","text":"(array([0., 1.], dtype=float32), array([70391, 70391]))\n(array([0., 1.], dtype=float32), array([12423, 12423]))\n(array([0., 1.], dtype=float32), array([11293, 11293]))\n","output_type":"stream"}]},{"cell_type":"code","source":"def get_callbacks():\n    return [\n        # ModelCheckpoint(\n        #     \"best_model.h5\", save_best_only=True, monitor=\"loss\"\n        # ),\n        # ReduceLROnPlateau(\n        #     monitor=\"val_top_k_categorical_accuracy\",\n        #     factor=0.2,\n        #     patience=2,\n        #     min_lr=0.000001,\n        # ),\n        EarlyStopping(\n            monitor=\"val_loss\",\n            min_delta=1e-3,\n            patience=10,\n            verbose=1,\n            mode=\"auto\",\n            baseline=None,\n            restore_best_weights=True,\n        ),\n    ]\n\n# https://arxiv.org/pdf/1611.08024.pdf\ndef EEGNet(n_classes, n_channels=64, n_samples=128, kernel_length=64, n_filters1=8, \n           n_filters2=16, depth_multiplier=2, norm_rate=0.25, dropout_rate=0.5, \n           dropoutType=\"Dropout\"):\n\n    if dropoutType == \"SpatialDropout2D\":\n        dropoutType=SpatialDropout2D\n    elif dropoutType == \"Dropout\":\n        dropoutType=Dropout\n\n    inputs = Input(shape=(n_channels, n_samples, 1))\n\n    block1 = Conv2D(n_filters1, (1, kernel_length), padding=\"same\", input_shape=(n_channels, n_samples, 1), use_bias=False)(inputs)\n    block1 = BatchNormalization()(block1)\n    block1 = DepthwiseConv2D((n_channels, 1), use_bias=False, depth_multiplier=depth_multiplier, depthwise_constraint=max_norm(1.0))(block1)\n    block1 = BatchNormalization()(block1)\n    block1 = Activation(\"elu\")(block1)\n    block1 = AveragePooling2D((1, 4))(block1)\n    block1 = dropoutType(dropout_rate)(block1)\n\n    block2 = SeparableConv2D(n_filters2, (1, 16), use_bias=False, padding=\"same\")(block1)\n    block2 = BatchNormalization()(block2)\n    block2 = Activation(\"elu\")(block2)\n    block2 = AveragePooling2D((1, 8))(block2)\n    block2 = dropoutType(dropout_rate)(block2)\n    block2 = Flatten(name=\"flatten\")(block2)\n\n    classifier = Dense(n_classes, name=\"dense\", kernel_constraint=max_norm(norm_rate))(block2)\n    classifier = Activation(\"softmax\", name=\"softmax\")(classifier)\n\n    model = Model(inputs=inputs, outputs=classifier) \n\n    optimizer = Adam(amsgrad=True, learning_rate=LEARNING_RATE)\n    loss = BinaryCrossentropy(from_logits=True)\n\n    model.compile(\n        optimizer=optimizer,\n        loss=loss,\n        metrics=[\n            TopKCategoricalAccuracy(k=3),\n            AUC(),\n            Precision(),\n            Recall(),\n        ],\n    )\n\n    model.summary()\n\n    return model","metadata":{"execution":{"iopub.status.busy":"2022-11-20T19:37:13.227741Z","iopub.execute_input":"2022-11-20T19:37:13.228102Z","iopub.status.idle":"2022-11-20T19:37:13.241110Z","shell.execute_reply.started":"2022-11-20T19:37:13.228065Z","shell.execute_reply":"2022-11-20T19:37:13.239866Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"def plot_history_metrics(history):\n    total_plots = len(history.history)\n    cols = total_plots // 2\n\n    rows = total_plots // cols\n\n    if total_plots % cols != 0:\n        rows += 1\n\n    pos = range(1, total_plots + 1)\n    plt.figure(figsize=(15, 10))\n    for i, (key, value) in enumerate(history.history.items()):\n        plt.subplot(rows, cols, pos[i])\n        plt.plot(range(len(value)), value)\n        plt.title(str(key))\n    plt.show()","metadata":{"execution":{"iopub.status.busy":"2022-11-20T19:37:13.242662Z","iopub.execute_input":"2022-11-20T19:37:13.243278Z","iopub.status.idle":"2022-11-20T19:37:13.254502Z","shell.execute_reply.started":"2022-11-20T19:37:13.243243Z","shell.execute_reply":"2022-11-20T19:37:13.253502Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"model = EEGNet(n_classes=N_CLASSES, n_channels=N_CHANNELS, n_samples=N_SAMPLES)","metadata":{"execution":{"iopub.status.busy":"2022-11-20T19:37:13.255960Z","iopub.execute_input":"2022-11-20T19:37:13.256350Z","iopub.status.idle":"2022-11-20T19:37:13.405417Z","shell.execute_reply.started":"2022-11-20T19:37:13.256280Z","shell.execute_reply":"2022-11-20T19:37:13.404469Z"},"trusted":true},"execution_count":7,"outputs":[{"name":"stdout","text":"Model: \"model\"\n_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\ninput_1 (InputLayer)         [(None, 25, 128, 1)]      0         \n_________________________________________________________________\nconv2d (Conv2D)              (None, 25, 128, 8)        512       \n_________________________________________________________________\nbatch_normalization (BatchNo (None, 25, 128, 8)        32        \n_________________________________________________________________\ndepthwise_conv2d (DepthwiseC (None, 1, 128, 16)        400       \n_________________________________________________________________\nbatch_normalization_1 (Batch (None, 1, 128, 16)        64        \n_________________________________________________________________\nactivation (Activation)      (None, 1, 128, 16)        0         \n_________________________________________________________________\naverage_pooling2d (AveragePo (None, 1, 32, 16)         0         \n_________________________________________________________________\ndropout (Dropout)            (None, 1, 32, 16)         0         \n_________________________________________________________________\nseparable_conv2d (SeparableC (None, 1, 32, 16)         512       \n_________________________________________________________________\nbatch_normalization_2 (Batch (None, 1, 32, 16)         64        \n_________________________________________________________________\nactivation_1 (Activation)    (None, 1, 32, 16)         0         \n_________________________________________________________________\naverage_pooling2d_1 (Average (None, 1, 4, 16)          0         \n_________________________________________________________________\ndropout_1 (Dropout)          (None, 1, 4, 16)          0         \n_________________________________________________________________\nflatten (Flatten)            (None, 64)                0         \n_________________________________________________________________\ndense (Dense)                (None, 2)                 130       \n_________________________________________________________________\nsoftmax (Activation)         (None, 2)                 0         \n=================================================================\nTotal params: 1,714\nTrainable params: 1,634\nNon-trainable params: 80\n_________________________________________________________________\n","output_type":"stream"}]},{"cell_type":"code","source":"history = model.fit(\n    train_dataset,\n    epochs=EPOCHS,\n    callbacks=get_callbacks(),\n    validation_data=valid_dataset,\n#     class_weight=???,\n)","metadata":{"execution":{"iopub.status.busy":"2022-11-20T19:37:13.407973Z","iopub.execute_input":"2022-11-20T19:37:13.408258Z","iopub.status.idle":"2022-11-20T19:38:22.668504Z","shell.execute_reply.started":"2022-11-20T19:37:13.408232Z","shell.execute_reply":"2022-11-20T19:38:22.667002Z"},"trusted":true},"execution_count":8,"outputs":[{"name":"stdout","text":"Epoch 1/5\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.7/site-packages/keras/backend.py:4994: UserWarning: \"`binary_crossentropy` received `from_logits=True`, but the `output` argument was produced by a sigmoid or softmax activation and thus does not represent logits. Was this intended?\"\n  '\"`binary_crossentropy` received `from_logits=True`, but the `output`'\n2022-11-20 19:37:17.809711: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:185] None of the MLIR Optimization Passes are enabled (registered 2)\n2022-11-20 19:37:18.930192: I tensorflow/stream_executor/cuda/cuda_dnn.cc:369] Loaded cuDNN version 8005\n","output_type":"stream"},{"name":"stdout","text":"1100/1100 [==============================] - 24s 14ms/step - loss: 0.1465 - top_k_categorical_accuracy: 1.0000 - auc: 1.0000 - precision: 0.9988 - recall: 0.9988 - val_loss: 0.0438 - val_top_k_categorical_accuracy: 1.0000 - val_auc: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\nEpoch 2/5\n1100/1100 [==============================] - 15s 14ms/step - loss: 0.0351 - top_k_categorical_accuracy: 1.0000 - auc: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0202 - val_top_k_categorical_accuracy: 1.0000 - val_auc: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\nEpoch 3/5\n1100/1100 [==============================] - 15s 14ms/step - loss: 0.0187 - top_k_categorical_accuracy: 1.0000 - auc: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0104 - val_top_k_categorical_accuracy: 1.0000 - val_auc: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\nEpoch 4/5\n 298/1100 [=======>......................] - ETA: 10s - loss: 0.0140 - top_k_categorical_accuracy: 1.0000 - auc: 1.0000 - precision: 1.0000 - recall: 1.0000","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m/tmp/ipykernel_23/901151987.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mEPOCHS\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mget_callbacks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m     \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalid_dataset\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;31m#     class_weight=???,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m )\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1187\u001b[0m               \u001b[0mlogs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtmp_logs\u001b[0m  \u001b[0;31m# No error, now safe to assign to logs.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1188\u001b[0m               \u001b[0mend_step\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstep\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep_increment\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1189\u001b[0;31m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mend_step\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1190\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstop_training\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1191\u001b[0m                 \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/keras/callbacks.py\u001b[0m in \u001b[0;36mon_train_batch_end\u001b[0;34m(self, batch, logs)\u001b[0m\n\u001b[1;32m    433\u001b[0m     \"\"\"\n\u001b[1;32m    434\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_should_call_train_batch_hooks\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 435\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_batch_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mModeKeys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTRAIN\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'end'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    436\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    437\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mon_test_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/keras/callbacks.py\u001b[0m in \u001b[0;36m_call_batch_hook\u001b[0;34m(self, mode, hook, batch, logs)\u001b[0m\n\u001b[1;32m    293\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_batch_begin_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    294\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'end'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 295\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_batch_end_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    296\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    297\u001b[0m       \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Unrecognized hook: {}'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/keras/callbacks.py\u001b[0m in \u001b[0;36m_call_batch_end_hook\u001b[0;34m(self, mode, batch, logs)\u001b[0m\n\u001b[1;32m    313\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_batch_times\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_time\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    314\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 315\u001b[0;31m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_batch_hook_helper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhook_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    316\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    317\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_batch_times\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_batches_for_timing_check\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/keras/callbacks.py\u001b[0m in \u001b[0;36m_call_batch_hook_helper\u001b[0;34m(self, hook_name, batch, logs)\u001b[0m\n\u001b[1;32m    351\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mcallback\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    352\u001b[0m       \u001b[0mhook\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcallback\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 353\u001b[0;31m       \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    354\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    355\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_timing\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/keras/callbacks.py\u001b[0m in \u001b[0;36mon_train_batch_end\u001b[0;34m(self, batch, logs)\u001b[0m\n\u001b[1;32m   1026\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1027\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mon_train_batch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1028\u001b[0;31m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_batch_update_progbar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1029\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1030\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mon_test_batch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/keras/callbacks.py\u001b[0m in \u001b[0;36m_batch_update_progbar\u001b[0;34m(self, batch, logs)\u001b[0m\n\u001b[1;32m   1099\u001b[0m       \u001b[0;31m# Only block async when verbose = 1.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1100\u001b[0m       \u001b[0mlogs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msync_to_numpy_or_python_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1101\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprogbar\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mseen\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfinalize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1102\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1103\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_finalize_progbar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcounter\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/keras/utils/generic_utils.py\u001b[0m in \u001b[0;36mupdate\u001b[0;34m(self, current, values, finalize)\u001b[0m\n\u001b[1;32m    971\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    972\u001b[0m       \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstdout\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 973\u001b[0;31m       \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstdout\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflush\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    974\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    975\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mverbose\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/ipykernel/iostream.py\u001b[0m in \u001b[0;36mflush\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    478\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpub_thread\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mschedule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mevt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    479\u001b[0m             \u001b[0;31m# and give a timeout to avoid\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 480\u001b[0;31m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mevt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflush_timeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    481\u001b[0m                 \u001b[0;31m# write directly to __stderr__ instead of warning because\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    482\u001b[0m                 \u001b[0;31m# if this is happening sys.stderr may be the problem.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    550\u001b[0m             \u001b[0msignaled\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_flag\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    551\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0msignaled\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 552\u001b[0;31m                 \u001b[0msignaled\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cond\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    553\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0msignaled\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    554\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    298\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    299\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 300\u001b[0;31m                     \u001b[0mgotit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwaiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    301\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    302\u001b[0m                     \u001b[0mgotit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwaiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "],"ename":"KeyboardInterrupt","evalue":"","output_type":"error"}]},{"cell_type":"code","source":"plot_history_metrics(history)","metadata":{"execution":{"iopub.status.busy":"2022-11-20T19:38:22.669849Z","iopub.status.idle":"2022-11-20T19:38:22.670591Z","shell.execute_reply.started":"2022-11-20T19:38:22.670325Z","shell.execute_reply":"2022-11-20T19:38:22.670355Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}