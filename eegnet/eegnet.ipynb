{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import mne\n",
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Dense, Activation, Permute, Dropout\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, AveragePooling2D\n",
    "from tensorflow.keras.layers import SeparableConv2D, DepthwiseConv2D\n",
    "from tensorflow.keras.layers import BatchNormalization\n",
    "from tensorflow.keras.layers import SpatialDropout2D\n",
    "from tensorflow.keras.regularizers import l1_l2\n",
    "from tensorflow.keras.layers import Input, Flatten\n",
    "from tensorflow.keras.constraints import max_norm\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras.losses import CategoricalCrossentropy\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.metrics import TopKCategoricalAccuracy, AUC, Precision, Recall\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, ReduceLROnPlateau, EarlyStopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BCICIV_PATH = \"../toy_data/BCICIV_2a_gdf\"\n",
    "BATCH_SIZE = 64\n",
    "SHUFFLE_BUFFER_SIZE = BATCH_SIZE * 2 \n",
    "\n",
    "EPOCHS = 5\n",
    "LEARNING_RATE = 1e-3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data():\n",
    "\treturn mne.io.read_raw_gdf(f'{BCICIV_PATH}/A01T.gdf')\n",
    "\n",
    "def visualize_data():\n",
    "\tpass\n",
    "\n",
    "def preprocess_data():\n",
    "\tpass\n",
    "\n",
    "def make_tf_dataset(X_train, y_train, X_valid, y_valid, X_test, y_test):\n",
    "\ttrain_dataset = tf.data.Dataset.from_tensor_slices((X_train, y_train))\n",
    "\tvalid_dataset = tf.data.Dataset.from_tensor_slices((X_valid, y_valid))\n",
    "\ttest_dataset = tf.data.Dataset.from_tensor_slices((X_test, y_test))\n",
    "\n",
    "\ttrain_dataset = train_dataset.shuffle(SHUFFLE_BUFFER_SIZE).batch(BATCH_SIZE)\n",
    "\tvalid_dataset = valid_dataset.shuffle(SHUFFLE_BUFFER_SIZE).batch(BATCH_SIZE)\n",
    "\ttest_dataset = test_dataset.batch(BATCH_SIZE)\n",
    "\n",
    "\treturn train_dataset, valid_dataset, test_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_callbacks():\n",
    "\treturn [\n",
    "\t\t# ModelCheckpoint(\n",
    "\t\t#     \"best_model.h5\", save_best_only=True, monitor=\"loss\"\n",
    "\t\t# ),\n",
    "\t\t# ReduceLROnPlateau(\n",
    "\t\t#     monitor=\"val_top_k_categorical_accuracy\",\n",
    "\t\t#     factor=0.2,\n",
    "\t\t#     patience=2,\n",
    "\t\t#     min_lr=0.000001,\n",
    "\t\t# ),\n",
    "\t\tEarlyStopping(\n",
    "\t\t\tmonitor=\"val_loss\",\n",
    "\t\t\tmin_delta=1e-3,\n",
    "\t\t\tpatience=10,\n",
    "\t\t\tverbose=1,\n",
    "\t\t\tmode=\"auto\",\n",
    "\t\t\tbaseline=None,\n",
    "\t\t\trestore_best_weights=True,\n",
    "\t\t),\n",
    "\t]\n",
    "\n",
    "def EEGNet(n_classes, channels=64, samples=128, kernel_length=64, n_filters1=8, n_filters2=16, depth_multiplier=2, norm_rate=0.25, dropout_rate=0.5, dropoutType=\"Dropout\"):\n",
    "\n",
    "\tif dropoutType == \"SpatialDropout2D\":\n",
    "\t\tdropoutType=SpatialDropout2D\n",
    "\telif dropoutType == \"Dropout\":\n",
    "\t\tdropoutType=Dropout\n",
    "\n",
    "\tinput = Input(shape=(channels, samples, 1))\n",
    "\n",
    "\tblock1 = Conv2D(n_filters1, (1, kernel_length), padding=\"same\", input_shape=(channels, samples, 1), use_bias=False)(input)\n",
    "\tblock1 = BatchNormalization()(block1)\n",
    "\tblock1 = DepthwiseConv2D((channels, 1), use_bias=False, depth_multiplier=depth_multiplier, depthwise_constraint=max_norm(1.0))(block1)\n",
    "\tblock1 = BatchNormalization()(block1)\n",
    "\tblock1 = Activation(\"elu\")(block1)\n",
    "\tblock1 = AveragePooling2D((1, 4))(block1)\n",
    "\tblock1 = dropoutType(dropout_rate)(block1)\n",
    "\n",
    "\tblock2 = SeparableConv2D(n_filters2, (1, 16), use_bias=False, padding=\"same\")(block1)\n",
    "\tblock2 = BatchNormalization()(block2)\n",
    "\tblock2 = Activation(\"elu\")(block2)\n",
    "\tblock2 = AveragePooling2D((1, 8))(block2)\n",
    "\tblock2 = dropoutType(dropout_rate)(block2)\n",
    "\tblock2 = Flatten(name=\"flatten\")(block2)\n",
    "\n",
    "\tclassifier = Dense(n_classes, name=\"dense\", kernel_constraint=max_norm(norm_rate))(block2)\n",
    "\tclassifier = Activation(\"softmax\", name=\"softmax\")(classifier)\n",
    "\n",
    "\tmodel = Model(inputs=input, outputs=classifier) \n",
    "\n",
    "\toptimizer = Adam(amsgrad=True, learning_rate=LEARNING_RATE)\n",
    "\tloss = CategoricalCrossentropy()\n",
    "\n",
    "\tmodel.compile(\n",
    "\t\toptimizer=optimizer,\n",
    "\t\tloss=loss,\n",
    "\t\tmetrics=[\n",
    "\t\t\tTopKCategoricalAccuracy(k=3),\n",
    "\t\t\tAUC(),\n",
    "\t\t\tPrecision(),\n",
    "\t\t\tRecall(),\n",
    "\t\t],\n",
    "\t)\n",
    "\n",
    "\tmodel.summary()\n",
    "\n",
    "\treturn model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_history_metrics(history):\n",
    "    total_plots = len(history.history)\n",
    "    cols = total_plots // 2\n",
    "\n",
    "    rows = total_plots // cols\n",
    "\n",
    "    if total_plots % cols != 0:\n",
    "        rows += 1\n",
    "\n",
    "    pos = range(1, total_plots + 1)\n",
    "    plt.figure(figsize=(15, 10))\n",
    "    for i, (key, value) in enumerate(history.history.items()):\n",
    "        plt.subplot(rows, cols, pos[i])\n",
    "        plt.plot(range(len(value)), value)\n",
    "        plt.title(str(key))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = load_data()\n",
    "visualize_data(data)\n",
    "X_train, y_train, X_valid, y_valid, X_test, y_test = preprocess_data(data)\n",
    "train_dataset, valid_dataset, test_dataset = make_tf_dataset(X_train, y_train, X_valid, y_valid, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = EEGNet(n_classes=???)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(\n",
    "    train_dataset,\n",
    "    epochs=EPOCHS,\n",
    "    callbacks=get_callbacks(),\n",
    "    validation_data=valid_dataset,\n",
    "    class_weight=???,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_history_metrics(history)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('deepdac')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "9bf73cbd865082e3cd06c05babb8829fd907c8e55c85361e30fff74a8577746e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
