{"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"vscode":{"interpreter":{"hash":"9bf73cbd865082e3cd06c05babb8829fd907c8e55c85361e30fff74a8577746e"}}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import numpy as np\nfrom matplotlib import pyplot as plt\nimport mne\nimport tensorflow as tf\nimport os\n\nfrom tensorflow.keras.models import Model\nfrom tensorflow.keras.layers import Dense, Activation, Permute, Dropout\nfrom tensorflow.keras.layers import Conv2D, MaxPooling2D, AveragePooling2D\nfrom tensorflow.keras.layers import SeparableConv2D, DepthwiseConv2D\nfrom tensorflow.keras.layers import BatchNormalization\nfrom tensorflow.keras.layers import SpatialDropout2D\nfrom tensorflow.keras.regularizers import l1_l2\nfrom tensorflow.keras.layers import Input, Flatten\nfrom tensorflow.keras.constraints import max_norm\nfrom tensorflow.keras import backend as K\nfrom tensorflow.keras.losses import CategoricalCrossentropy\nfrom tensorflow.keras.optimizers import Adam\nfrom tensorflow.keras.metrics import TopKCategoricalAccuracy, AUC, Precision, Recall\nfrom tensorflow.keras.callbacks import ModelCheckpoint, ReduceLROnPlateau, EarlyStopping","metadata":{"execution":{"iopub.status.busy":"2022-11-18T14:41:12.368481Z","iopub.execute_input":"2022-11-18T14:41:12.369028Z","iopub.status.idle":"2022-11-18T14:41:12.381108Z","shell.execute_reply.started":"2022-11-18T14:41:12.368982Z","shell.execute_reply":"2022-11-18T14:41:12.379877Z"},"trusted":true},"execution_count":74,"outputs":[]},{"cell_type":"code","source":"N_FILES = 3\n\nWHERE = \"kaggle\"\nif WHERE==\"colab\":\n    BCICIV_PATH = \"/content/BCICIV_2a_gdf\"\n    BATCH_SIZE = 32\nelif WHERE==\"kaggle\":\n    BCICIV_PATH = \"../input/eeg-data-augmentation/BCICIV_2a_gdf\"\n    BATCH_SIZE = 64\nelif WHERE==\"home\":\n    PATH_LABELS = \"../toy_data/BCICIV_2a_gdf\"\n    BATCH_SIZE = 4\nSHUFFLE_BUFFER_SIZE = BATCH_SIZE * 2 \n\nEPOCHS = 5\nLEARNING_RATE = 1e-3","metadata":{"execution":{"iopub.status.busy":"2022-11-18T14:41:12.530616Z","iopub.execute_input":"2022-11-18T14:41:12.531449Z","iopub.status.idle":"2022-11-18T14:41:12.538960Z","shell.execute_reply.started":"2022-11-18T14:41:12.531403Z","shell.execute_reply":"2022-11-18T14:41:12.537788Z"},"trusted":true},"execution_count":75,"outputs":[]},{"cell_type":"code","source":"def load_data():\n    files = []\n    cpt = 0\n    for filename in os.listdir(BCICIV_PATH):\n        if cpt >= N_FILES:\n            break\n        files.append(mne.io.read_raw_gdf(f'{BCICIV_PATH}/{filename}'))\n        cpt += 1\n    return files\n\n## NEED TO DO A STRATIFIED SPLIT ACCROSS THE DIFFERENT USER OF THE EXPERIMENT !!!\ndef preprocess_data(data):\n#     print(data.info)\n#     data.compute_psd().plot()\n#     plt.show()\n    preprocessed_data = data[0].get_data()\n    for d in data[1:]:\n        preprocessed_data = np.concatenate((preprocessed_data, d.get_data()), axis=1)\n    n_chans, n_steps = preprocessed_data.shape\n    print(\"--> This dataset contains\", n_chans, \"channels and\", n_steps, \"steps\")\n    print(\"--> 25 channels: 22 EEG and 3 EOG\")\n    return preprocessed_data\n#     return X_train, y_train, X_valid, y_valid, X_test, y_test \n\ndef visualize_data():\n    pass\n\ndef make_tf_dataset(X_train, y_train, X_valid, y_valid, X_test, y_test):\n    train_dataset = tf.data.Dataset.from_tensor_slices((X_train, y_train))\n    valid_dataset = tf.data.Dataset.from_tensor_slices((X_valid, y_valid))\n    test_dataset = tf.data.Dataset.from_tensor_slices((X_test, y_test))\n\n    train_dataset = train_dataset.shuffle(SHUFFLE_BUFFER_SIZE).batch(BATCH_SIZE)\n    valid_dataset = valid_dataset.shuffle(SHUFFLE_BUFFER_SIZE).batch(BATCH_SIZE)\n    test_dataset = test_dataset.batch(BATCH_SIZE)\n\n    return train_dataset, valid_dataset, test_dataset","metadata":{"execution":{"iopub.status.busy":"2022-11-18T14:41:12.713187Z","iopub.execute_input":"2022-11-18T14:41:12.713990Z","iopub.status.idle":"2022-11-18T14:41:12.727366Z","shell.execute_reply.started":"2022-11-18T14:41:12.713947Z","shell.execute_reply":"2022-11-18T14:41:12.726311Z"},"trusted":true},"execution_count":76,"outputs":[]},{"cell_type":"code","source":"data = load_data()\npreprocess_data(data)\n# X_train, y_train, X_valid, y_valid, X_test, y_test = preprocess_data(data)","metadata":{"execution":{"iopub.status.busy":"2022-11-18T14:41:12.898167Z","iopub.execute_input":"2022-11-18T14:41:12.898799Z","iopub.status.idle":"2022-11-18T14:41:17.647728Z","shell.execute_reply.started":"2022-11-18T14:41:12.898754Z","shell.execute_reply":"2022-11-18T14:41:17.646531Z"},"trusted":true},"execution_count":77,"outputs":[{"name":"stdout","text":"Extracting EDF parameters from /kaggle/input/eeg-data-augmentation/BCICIV_2a_gdf/A01T.gdf...\nGDF file detected\nSetting channel info structure...\nCould not determine channel type of the following channels, they will be set as EEG:\nEEG-Fz, EEG, EEG, EEG, EEG, EEG, EEG, EEG-C3, EEG, EEG-Cz, EEG, EEG-C4, EEG, EEG, EEG, EEG, EEG, EEG, EEG, EEG-Pz, EEG, EEG, EOG-left, EOG-central, EOG-right\nCreating raw.info structure...\nExtracting EDF parameters from /kaggle/input/eeg-data-augmentation/BCICIV_2a_gdf/A04E.gdf...\nGDF file detected\nSetting channel info structure...\nCould not determine channel type of the following channels, they will be set as EEG:\nEEG-Fz, EEG, EEG, EEG, EEG, EEG, EEG, EEG-C3, EEG, EEG-Cz, EEG, EEG-C4, EEG, EEG, EEG, EEG, EEG, EEG, EEG, EEG-Pz, EEG, EEG, EOG-left, EOG-central, EOG-right\nCreating raw.info structure...\nExtracting EDF parameters from /kaggle/input/eeg-data-augmentation/BCICIV_2a_gdf/A08T.gdf...\nGDF file detected\nSetting channel info structure...\nCould not determine channel type of the following channels, they will be set as EEG:\nEEG-Fz, EEG, EEG, EEG, EEG, EEG, EEG, EEG-C3, EEG, EEG-Cz, EEG, EEG-C4, EEG, EEG, EEG, EEG, EEG, EEG, EEG, EEG-Pz, EEG, EEG, EOG-left, EOG-central, EOG-right\nCreating raw.info structure...\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.7/contextlib.py:119: RuntimeWarning: Channel names are not unique, found duplicates for: {'EEG'}. Applying running numbers for duplicates.\n  next(self.gen)\n/opt/conda/lib/python3.7/contextlib.py:119: RuntimeWarning: Channel names are not unique, found duplicates for: {'EEG'}. Applying running numbers for duplicates.\n  next(self.gen)\n/opt/conda/lib/python3.7/contextlib.py:119: RuntimeWarning: Channel names are not unique, found duplicates for: {'EEG'}. Applying running numbers for duplicates.\n  next(self.gen)\n","output_type":"stream"},{"name":"stdout","text":"--> This dataset contains 25 channels and 2007845 steps\n--> 25 channels: 22 EEG and 3 EOG\n","output_type":"stream"},{"execution_count":77,"output_type":"execute_result","data":{"text/plain":"array([[-2.11425781e-05, -2.19238281e-05, -1.56250000e-05, ...,\n        -8.93554688e-06, -2.05078125e-06, -2.24609375e-06],\n       [-2.36816406e-05, -2.39257812e-05, -1.97265625e-05, ...,\n        -1.23046875e-05, -5.12695312e-06, -6.64062500e-06],\n       [-2.14843750e-05, -2.43164062e-05, -1.88476562e-05, ...,\n        -7.03125000e-06, -1.46484375e-06, -2.63671875e-06],\n       ...,\n       [ 3.17382813e-05,  2.24609375e-05,  3.36914062e-05, ...,\n        -2.44140625e-06,  4.39453125e-06, -1.95312500e-06],\n       [-1.36718750e-05, -1.31835937e-05, -8.30078125e-06, ...,\n        -5.85937500e-06, -9.76562500e-07, -4.39453125e-06],\n       [-4.39453125e-05, -4.05273437e-05, -3.85742188e-05, ...,\n        -5.37109375e-06,  0.00000000e+00, -3.90625000e-06]])"},"metadata":{}}]},{"cell_type":"code","source":"def get_callbacks():\n    return [\n        # ModelCheckpoint(\n        #     \"best_model.h5\", save_best_only=True, monitor=\"loss\"\n        # ),\n        # ReduceLROnPlateau(\n        #     monitor=\"val_top_k_categorical_accuracy\",\n        #     factor=0.2,\n        #     patience=2,\n        #     min_lr=0.000001,\n        # ),\n        EarlyStopping(\n            monitor=\"val_loss\",\n            min_delta=1e-3,\n            patience=10,\n            verbose=1,\n            mode=\"auto\",\n            baseline=None,\n            restore_best_weights=True,\n        ),\n    ]\n\ndef EEGNet(n_classes, channels=64, samples=128, kernel_length=64, n_filters1=8, n_filters2=16, depth_multiplier=2, norm_rate=0.25, dropout_rate=0.5, dropoutType=\"Dropout\"):\n\n    if dropoutType == \"SpatialDropout2D\":\n        dropoutType=SpatialDropout2D\n    elif dropoutType == \"Dropout\":\n        dropoutType=Dropout\n\n    input = Input(shape=(channels, samples, 1))\n\n    block1 = Conv2D(n_filters1, (1, kernel_length), padding=\"same\", input_shape=(channels, samples, 1), use_bias=False)(input)\n    block1 = BatchNormalization()(block1)\n    block1 = DepthwiseConv2D((channels, 1), use_bias=False, depth_multiplier=depth_multiplier, depthwise_constraint=max_norm(1.0))(block1)\n    block1 = BatchNormalization()(block1)\n    block1 = Activation(\"elu\")(block1)\n    block1 = AveragePooling2D((1, 4))(block1)\n    block1 = dropoutType(dropout_rate)(block1)\n\n    block2 = SeparableConv2D(n_filters2, (1, 16), use_bias=False, padding=\"same\")(block1)\n    block2 = BatchNormalization()(block2)\n    block2 = Activation(\"elu\")(block2)\n    block2 = AveragePooling2D((1, 8))(block2)\n    block2 = dropoutType(dropout_rate)(block2)\n    block2 = Flatten(name=\"flatten\")(block2)\n\n    classifier = Dense(n_classes, name=\"dense\", kernel_constraint=max_norm(norm_rate))(block2)\n    classifier = Activation(\"softmax\", name=\"softmax\")(classifier)\n\n    model = Model(inputs=input, outputs=classifier) \n\n    optimizer = Adam(amsgrad=True, learning_rate=LEARNING_RATE)\n    loss = CategoricalCrossentropy()\n\n    model.compile(\n        optimizer=optimizer,\n        loss=loss,\n        metrics=[\n            TopKCategoricalAccuracy(k=3),\n            AUC(),\n            Precision(),\n            Recall(),\n        ],\n    )\n\n    model.summary()\n\n    return model","metadata":{"execution":{"iopub.status.busy":"2022-11-18T14:41:17.649576Z","iopub.execute_input":"2022-11-18T14:41:17.649980Z","iopub.status.idle":"2022-11-18T14:41:17.665079Z","shell.execute_reply.started":"2022-11-18T14:41:17.649947Z","shell.execute_reply":"2022-11-18T14:41:17.663740Z"},"trusted":true},"execution_count":78,"outputs":[]},{"cell_type":"code","source":"def plot_history_metrics(history):\n    total_plots = len(history.history)\n    cols = total_plots // 2\n\n    rows = total_plots // cols\n\n    if total_plots % cols != 0:\n        rows += 1\n\n    pos = range(1, total_plots + 1)\n    plt.figure(figsize=(15, 10))\n    for i, (key, value) in enumerate(history.history.items()):\n        plt.subplot(rows, cols, pos[i])\n        plt.plot(range(len(value)), value)\n        plt.title(str(key))\n    plt.show()","metadata":{"execution":{"iopub.status.busy":"2022-11-18T14:39:37.292629Z","iopub.execute_input":"2022-11-18T14:39:37.293077Z","iopub.status.idle":"2022-11-18T14:39:37.306513Z","shell.execute_reply.started":"2022-11-18T14:39:37.293034Z","shell.execute_reply":"2022-11-18T14:39:37.305173Z"},"trusted":true},"execution_count":71,"outputs":[]},{"cell_type":"code","source":"# data = load_data()\n# X_train, y_train, X_valid, y_valid, X_test, y_test = preprocess_data(data)\n# visualize_data(data)\n# train_dataset, valid_dataset, test_dataset = make_tf_dataset(X_train, y_train, X_valid, y_valid, X_test, y_test)","metadata":{"execution":{"iopub.status.busy":"2022-11-18T14:39:37.307994Z","iopub.execute_input":"2022-11-18T14:39:37.308395Z","iopub.status.idle":"2022-11-18T14:39:37.321718Z","shell.execute_reply.started":"2022-11-18T14:39:37.308362Z","shell.execute_reply":"2022-11-18T14:39:37.320667Z"},"trusted":true},"execution_count":72,"outputs":[]},{"cell_type":"code","source":"model = EEGNet(n_classes=???)","metadata":{"execution":{"iopub.status.busy":"2022-11-18T14:39:37.325094Z","iopub.execute_input":"2022-11-18T14:39:37.325440Z","iopub.status.idle":"2022-11-18T14:39:37.336628Z","shell.execute_reply.started":"2022-11-18T14:39:37.325411Z","shell.execute_reply":"2022-11-18T14:39:37.334754Z"},"trusted":true},"execution_count":73,"outputs":[{"traceback":["\u001b[0;36m  File \u001b[0;32m\"/tmp/ipykernel_27/667406098.py\"\u001b[0;36m, line \u001b[0;32m1\u001b[0m\n\u001b[0;31m    model = EEGNet(n_classes=???)\u001b[0m\n\u001b[0m                             ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"],"ename":"SyntaxError","evalue":"invalid syntax (667406098.py, line 1)","output_type":"error"}]},{"cell_type":"code","source":"history = model.fit(\n    train_dataset,\n    epochs=EPOCHS,\n    callbacks=get_callbacks(),\n    validation_data=valid_dataset,\n    class_weight=???,\n)","metadata":{"execution":{"iopub.status.busy":"2022-11-18T14:39:37.337800Z","iopub.status.idle":"2022-11-18T14:39:37.338197Z","shell.execute_reply.started":"2022-11-18T14:39:37.338009Z","shell.execute_reply":"2022-11-18T14:39:37.338028Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plot_history_metrics(history)","metadata":{"execution":{"iopub.status.busy":"2022-11-18T14:39:37.339125Z","iopub.status.idle":"2022-11-18T14:39:37.339587Z","shell.execute_reply.started":"2022-11-18T14:39:37.339312Z","shell.execute_reply":"2022-11-18T14:39:37.339329Z"},"trusted":true},"execution_count":null,"outputs":[]}]}